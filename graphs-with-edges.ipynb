{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Graph Autoencoder (GAE) for Anomaly Detection on Event Graphs\n\nThis notebook builds a flexible **Graph Autoencoder** for anomaly detection,\nusing **PyTorch Geometric**.\n\n**Design choices:**\n\n- Events → graphs:\n  - Nodes = physics objects (jets, e, μ, γ, MET).\n  - Node features: `[pT, η, φ, one-hot(type)]`.\n  - Empty objects are dropped (based on `pT <= 0`).\n  - Fully connected directed graphs (all pairs `i ≠ j`).\n  - Edge attributes include:\n    - `Δη`, `Δφ` (wrapped to `[-π, π]`), `ΔR`,\n    - `log(pT_i + ε)`, `log(pT_j + ε)`,\n    - `(pT_i - pT_j) / (pT_i + pT_j + ε)`.\n\n- Labels:\n  - `target == \"EB_test\"` → **background** (label 0).\n  - Everything else → **signal** (label 1).\n  - Train **only on background**, test on background + signal.\n\n- Convolution types (configurable):\n  - `SAGEConv` (ignores edge_attr, baseline).\n  - `NNConv` (edge_attr → dynamic filters).\n  - `GINEConv` (edge-aware GIN).\n  - `TransformerConv` (attention with edge_attr).\n\n- Loss:\n  - Node feature **MSE** + optional **exponential loss**:\n\n$$\nL = \\text{MSE} + \\alpha \\, \\mathbb{E}\\big[\\exp(\\beta \\cdot \\text{MSE}_\\text{node}) - 1\\big]\n$$\n\n\n- Visualisations:\n  - Training / validation loss curves.\n  - Anomaly score histograms + ROC AUC.\n  - Latent space (PCA, optional t-SNE).\n  - η–φ plots: **input vs reconstruction**, using your provided functions.\n  - All plots are saved under a chosen `exp_dir` directory.\n\n- Hyperparameter grid search:\n  - Simple loop over a small config grid (conv type, hidden size, latent size, lr, etc.).\n","metadata":{"id":"ZTQMkUnLIAav"}},{"cell_type":"code","source":"# All non-PyTorch imports here\n\nimport os\nimport sys\nimport math\nimport copy\n\nimport pickle\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\n# For reproducibility\nimport random\n\nSEED = 42\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\n\n# Colab drive (only needed if you actually run in Google Colab)\n# from google.colab import drive\n# drive.mount('/content/drive')\n","metadata":{"id":"YuU0HDKZeweY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"62d5beee-c8ab-447e-8e8b-2a9e86b490fe","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:09:02.458264Z","iopub.execute_input":"2025-12-05T08:09:02.458490Z","iopub.status.idle":"2025-12-05T08:09:05.344511Z","shell.execute_reply.started":"2025-12-05T08:09:02.458467Z","shell.execute_reply":"2025-12-05T08:09:05.343853Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"modules_to_check = [\n    \"torch_scatter\",\n    \"torch_sparse\",\n    \"torch_cluster\",\n    \"torch_spline_conv\",\n    \"torch_geometric\",\n]\n\nprint(\"--- Checking PyTorch Geometric related module installations ---\")\nfor module_name in modules_to_check:\n    try:\n        __import__(module_name)\n        print(f\"{module_name}: Installed\")\n    except ImportError:\n        print(f\"{module_name}: NOT installed\")\nprint(\"----------------------------------------------------------\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iwlj4IBsCn0H","outputId":"1a80437b-0fd2-469a-eb87-24738194cef9","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:09:05.345997Z","iopub.execute_input":"2025-12-05T08:09:05.346384Z","iopub.status.idle":"2025-12-05T08:09:05.352649Z","shell.execute_reply.started":"2025-12-05T08:09:05.346365Z","shell.execute_reply":"2025-12-05T08:09:05.351946Z"}},"outputs":[{"name":"stdout","text":"--- Checking PyTorch Geometric related module installations ---\ntorch_scatter: NOT installed\ntorch_sparse: NOT installed\ntorch_cluster: NOT installed\ntorch_spline_conv: NOT installed\ntorch_geometric: NOT installed\n----------------------------------------------------------\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Install PyTorch Geometric and dependencies\n\n# Typical Colab install sequence; you may adjust CUDA versions if needed.\n!pip install -q torch-scatter torch-sparse torch-cluster torch-geometric\n\nimport torch\nprint(\"Torch version (after install):\", torch.__version__)\n","metadata":{"id":"tUdi7FVGxpuD","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:09:05.354238Z","iopub.execute_input":"2025-12-05T08:09:05.354547Z","iopub.status.idle":"2025-12-05T09:00:10.915119Z","shell.execute_reply.started":"2025-12-05T08:09:05.354511Z","shell.execute_reply":"2025-12-05T09:00:10.914297Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\nTorch version (after install): 2.6.0+cu124\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# All PyTorch / PyTorch Geometric related imports here\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom torch.utils.data import random_split\n\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import (\n    SAGEConv,\n    NNConv,\n    GINEConv,\n    TransformerConv,\n    global_mean_pool,\n)\n","metadata":{"id":"gYRqOatpxpju","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T09:00:10.916232Z","iopub.execute_input":"2025-12-05T09:00:10.916788Z","iopub.status.idle":"2025-12-05T09:00:19.220904Z","shell.execute_reply.started":"2025-12-05T09:00:10.916764Z","shell.execute_reply":"2025-12-05T09:00:19.220302Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Set plotting style at module level\nplt.rcParams.update({\n    # Font sizes\n    'font.size': 18,\n    'axes.labelsize': 18,\n    'axes.titlesize': 18,\n    'xtick.labelsize': 16,\n    'ytick.labelsize': 16,\n    'legend.fontsize': 16,\n    'legend.frameon': False,  # No box around legend\n    'axes.grid': False,\n    # Tick settings\n    'xtick.direction': 'in',\n    'ytick.direction': 'in',\n    'xtick.major.size': 10,\n    'ytick.major.size': 10,\n    'xtick.minor.size': 5,\n    'ytick.minor.size': 5,\n    'xtick.major.width': 1,\n    'ytick.major.width': 1,\n    'xtick.top': True,\n    'ytick.right': True,\n    'xtick.minor.visible': True,\n    'ytick.minor.visible': True\n})","metadata":{"id":"6h74igsd8tiP","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T09:00:19.221694Z","iopub.execute_input":"2025-12-05T09:00:19.222148Z","iopub.status.idle":"2025-12-05T09:00:19.226601Z","shell.execute_reply.started":"2025-12-05T09:00:19.222121Z","shell.execute_reply":"2025-12-05T09:00:19.225838Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"with open(\"/kaggle/input/balanced-with-dr-or/balanced_dfs_no_dup_OR.pkl\", \"rb\") as f:\n    ML_dict = pickle.load(f)","metadata":{"id":"bKCcKEStfZgk","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T09:00:19.230983Z","iopub.execute_input":"2025-12-05T09:00:19.231215Z","iopub.status.idle":"2025-12-05T09:00:22.435890Z","shell.execute_reply.started":"2025-12-05T09:00:19.231200Z","shell.execute_reply":"2025-12-05T09:00:22.435309Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Details of the data\nML_dict is a dictionary with the dataframes\n\n```\n'all_signals', 'HAHMggf', 'HNLeemu', 'HtoSUEP',\n'VBF_H125_a55a55_4b_ctau1_filtered', 'Znunu',\n'ggF_H125_a16a16_4b_ctau10_filtered', 'hh_bbbb_vbf_novhh_5fs_l1cvv1cv1'\n```\nAll of them have the same columns:\n\n```\n'j0pt', 'j0eta', 'j0phi', 'j1pt', 'j1eta', 'j1phi', 'j2pt', 'j2eta',\n       'j2phi', 'j3pt', 'j3eta', 'j3phi', 'j4pt', 'j4eta', 'j4phi', 'j5pt',\n       'j5eta', 'j5phi', 'e0pt', 'e0eta', 'e0phi', 'e1pt', 'e1eta', 'e1phi',\n       'e2pt', 'e2eta', 'e2phi', 'mu0pt', 'mu0eta', 'mu0phi', 'mu1pt',\n       'mu1eta', 'mu1phi', 'mu2pt', 'mu2eta', 'mu2phi', 'ph0pt', 'ph0eta',\n       'ph0phi', 'ph1pt', 'ph1eta', 'ph1phi', 'ph2pt', 'ph2eta', 'ph2phi',\n       'METpt', 'METeta', 'METphi', 'run_number', 'event_number', 'weight',\n       'target'\n```\nWhen loaded with `balanced_dfs_no_dup_processed.pkl`, the dataframes contain events for which there are no duplicate objects. Events with undefined METpt have been removed. All events where all objects have 0 pt have been removed. All of them have equal amount of signal and background ('target' == 'EB_test').\n\nWhen loaded with `balanced_dfs_no_dup_OR.pkl`, in addition to the above mentioned processing, overlap removal has also been performed.","metadata":{"id":"BZ6_B4Zj3cnb"}},{"cell_type":"code","source":"","metadata":{"id":"fo2mix9Cbrz1"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define object types and layout of columns in the DataFrame\n\nOBJ_TYPES = [\"MET\", \"e\", \"j\", \"mu\", \"ph\"]  # order matters for one-hot and plots\n\n# How many of each object (based on your column naming)\nN_JETS = 6   # j0..j5\nN_ELEC = 3   # e0..e2\nN_MU   = 3   # mu0..mu2\nN_PH   = 3   # ph0..ph2\n\n# Specification of objects and their (pt, eta, phi) columns\nOBJECT_SPECS = [\n    (\"MET\", [(\"METpt\", \"METeta\", \"METphi\")]),\n    (\"e\",   [(f\"e{i}pt\",  f\"e{i}eta\",  f\"e{i}phi\")  for i in range(N_ELEC)]),\n    (\"j\",   [(f\"j{i}pt\",  f\"j{i}eta\",  f\"j{i}phi\")  for i in range(N_JETS)]),\n    (\"mu\",  [(f\"mu{i}pt\", f\"mu{i}eta\", f\"mu{i}phi\") for i in range(N_MU)]),\n    (\"ph\",  [(f\"ph{i}pt\", f\"ph{i}eta\", f\"ph{i}phi\") for i in range(N_PH)]),\n]\n\ndef object_type_index(obj_type):\n    return OBJ_TYPES.index(obj_type)\n\nprint(\"OBJECT_SPECS defined with types:\", [t for t, _ in OBJECT_SPECS])\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"shY96qIauzTY","outputId":"c67fa56c-fcce-4483-cc1c-1d600bedee34","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T09:00:22.436607Z","iopub.execute_input":"2025-12-05T09:00:22.436829Z","iopub.status.idle":"2025-12-05T09:00:22.443192Z","shell.execute_reply.started":"2025-12-05T09:00:22.436803Z","shell.execute_reply":"2025-12-05T09:00:22.442594Z"}},"outputs":[{"name":"stdout","text":"OBJECT_SPECS defined with types: ['MET', 'e', 'j', 'mu', 'ph']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## All helper functions","metadata":{"id":"C3aVA8deyqjw"}},{"cell_type":"markdown","source":"### Fit node feature scaler (pT, η, φ)\n\nWe will standardize node features `[pT, η, φ]` over all **background training** nodes.\n\nNode features per node:\n- `[scaled_pT, scaled_η, scaled_φ, one-hot(type)]`\n\nEdge attributes use **log pT** and geometric differences. We keep them in natural units (no extra scaler)\nfor simplicity, but this can be extended.\n","metadata":{"id":"5de8EVYyy9rm"}},{"cell_type":"code","source":"# --- Node feature scaler helpers ---\n\ndef is_empty_object(pt, eta, phi):\n    \"\"\"\n    Criterion to drop empty objects.\n    Here we use pT <= 0 as 'empty' (adjust if needed).\n    \"\"\"\n    return pt <= 0\n\ndef collect_node_features_for_scaler(df):\n    \"\"\"\n    Collect [pt, eta, phi] from all non-empty nodes in a dataframe\n    to fit the StandardScaler on background training events.\n    \"\"\"\n    all_feats = []\n    for _, row in df.iterrows():\n        for obj_type, fields in OBJECT_SPECS:\n            for pt_col, eta_col, phi_col in fields:\n                pt = row[pt_col]\n                eta = row[eta_col]\n                phi = row[phi_col]\n                if is_empty_object(pt, eta, phi):\n                    continue\n                all_feats.append([pt, eta, phi])\n    if len(all_feats) == 0:\n        return np.zeros((0, 3))\n    return np.array(all_feats)\n\ndef fit_node_feature_scaler(df_bg_train):\n    \"\"\"\n    Fit a StandardScaler for [pt, eta, phi] on background training events.\n    \"\"\"\n    X_node_bg_train = collect_node_features_for_scaler(df_bg_train)\n    print(\"Collected node feature samples for scaler:\", X_node_bg_train.shape)\n    scaler = StandardScaler()\n    scaler.fit(X_node_bg_train)\n    print(\"Node feature scaler mean:\", scaler.mean_)\n    print(\"Node feature scaler scale:\", scaler.scale_)\n    return scaler\n\n# We'll assign node_feature_scaler inside the driver\nnode_feature_scaler = None\n","metadata":{"id":"o52YLjUyuzL7","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T09:00:22.443917Z","iopub.execute_input":"2025-12-05T09:00:22.444160Z","iopub.status.idle":"2025-12-05T09:00:22.472294Z","shell.execute_reply.started":"2025-12-05T09:00:22.444136Z","shell.execute_reply":"2025-12-05T09:00:22.471632Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### Graph construction utilities\n\nWe now define:\n\n- `build_event_graph(row, edge_attr_mode)`:\n  - builds `torch_geometric.data.Data` for a single event.\n\n- `build_graph_dataset(df, edge_attr_mode)`:\n  - builds a list of graphs from a DataFrame.\n\nEdge attribute modes:\n- `\"geo\"`: `[Δη, Δφ, ΔR]`\n- `\"geo_pt\"`: `[Δη, Δφ, ΔR, log(pT_i + ε), log(pT_j + ε), frac_diff]`\n","metadata":{"id":"UTrWqrvwzH8R"}},{"cell_type":"code","source":"def wrap_delta_phi(dphi):\n    \"\"\"\n    Wrap Δφ into [-π, π].\n    \"\"\"\n    return (dphi + np.pi) % (2 * np.pi) - np.pi\n\n\ndef build_event_graph(row, edge_attr_mode=\"geo_pt\"):\n    \"\"\"\n    Build a PyG Data object for a single event (row from DataFrame).\n    Node features: [scaled_pT, scaled_eta, scaled_phi, one-hot(type)]\n    Edge attributes: depends on edge_attr_mode.\n    \"\"\"\n    global node_feature_scaler\n    if node_feature_scaler is None:\n        raise RuntimeError(\"node_feature_scaler is not fitted yet. Call fit_node_feature_scaler first.\")\n\n    node_raw_feats = []   # [ [pt, eta, phi, type_idx], ... ]\n    labels = int(row[\"y\"])\n    weight = float(row.get(\"weight\", 1.0))\n\n    # Collect nodes\n    for obj_type, fields in OBJECT_SPECS:\n        t_idx = object_type_index(obj_type)\n        for pt_col, eta_col, phi_col in fields:\n            pt = float(row[pt_col])\n            eta = float(row[eta_col])\n            phi = float(row[phi_col])\n            if is_empty_object(pt, eta, phi):\n                continue\n            node_raw_feats.append([pt, eta, phi, t_idx])\n\n    if len(node_raw_feats) == 0:\n        # If an event has no valid nodes, skip it (rare, but just in case)\n        return None\n\n    node_raw_feats = np.array(node_raw_feats)  # [N, 4]\n    pts = node_raw_feats[:, 0]\n    etas = node_raw_feats[:, 1]\n    phis = node_raw_feats[:, 2]\n    t_indices = node_raw_feats[:, 3].astype(int)\n\n    # Scale [pt, eta, phi]\n    scaled_pep = node_feature_scaler.transform(node_raw_feats[:, :3])  # [N, 3]\n\n    # One-hot encode types\n    num_node_types = len(OBJ_TYPES)\n    one_hot = np.zeros((len(t_indices), num_node_types), dtype=np.float32)\n    one_hot[np.arange(len(t_indices)), t_indices] = 1.0\n\n    x_np = np.concatenate([scaled_pep, one_hot], axis=1).astype(np.float32)  # [N, 3+5]\n    x = torch.tensor(x_np, dtype=torch.float32)\n\n    num_nodes = x.shape[0]\n\n    # Fully connected directed edges (i != j)\n    src = []\n    dst = []\n    for i in range(num_nodes):\n        for j in range(num_nodes):\n            if i == j:\n                continue\n            src.append(i)\n            dst.append(j)\n    edge_index = torch.tensor([src, dst], dtype=torch.long)\n\n    # Edge attributes\n    edge_attrs = []\n    eps = 1e-6\n\n    for s, d in zip(src, dst):\n        deta = etas[s] - etas[d]\n        dphi = wrap_delta_phi(phis[s] - phis[d])\n        dR = math.sqrt(deta**2 + dphi**2)\n\n        if edge_attr_mode == \"geo\":\n            edge_attrs.append([deta, dphi, dR])\n        elif edge_attr_mode == \"geo_pt\":\n            log_pt_s = math.log(pts[s] + 1.0)\n            log_pt_d = math.log(pts[d] + 1.0)\n            frac_diff = (pts[s] - pts[d]) / (pts[s] + pts[d] + eps)\n            edge_attrs.append([deta, dphi, dR, log_pt_s, log_pt_d, frac_diff])\n        else:\n            raise ValueError(f\"Unknown edge_attr_mode: {edge_attr_mode}\")\n\n    edge_attr = torch.tensor(np.array(edge_attrs, dtype=np.float32), dtype=torch.float32)\n\n    data = Data(\n        x=x,\n        edge_index=edge_index,\n        edge_attr=edge_attr,\n        y=torch.tensor([labels], dtype=torch.long),\n        weight=torch.tensor([weight], dtype=torch.float32),\n    )\n\n    return data\n\n\ndef build_graph_dataset(df, edge_attr_mode=\"geo_pt\"):\n    graphs = []\n    labels = []\n    sample_labels = []\n    for _, row in df.iterrows():\n        g = build_event_graph(row, edge_attr_mode=edge_attr_mode)\n        if g is None:\n            continue\n        graphs.append(g)\n        labels.append(int(row[\"y\"]))\n        sample_labels.append(row.get(\"sample_label\", \"unknown\"))\n    return graphs, np.array(labels), np.array(sample_labels)\n","metadata":{"id":"y9t_8uV1uzJg","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T09:00:22.473069Z","iopub.execute_input":"2025-12-05T09:00:22.473299Z","iopub.status.idle":"2025-12-05T09:00:22.491302Z","shell.execute_reply.started":"2025-12-05T09:00:22.473277Z","shell.execute_reply":"2025-12-05T09:00:22.490595Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def build_conv_layer(conv_type, in_channels, out_channels, edge_dim=None, conv_config=None):\n    \"\"\"\n    Factory for different graph conv layers, now with conv-specific hyperparameters\n    provided via conv_config (a dict).\n\n    Supported conv_type values:\n      - 'sage'\n      - 'nn'\n      - 'gine'\n      - 'transformer'\n    \"\"\"\n    conv_type = conv_type.lower()\n    cfg = conv_config or {}\n\n    if conv_type == \"sage\":\n        # SAGEConv-specific hyperparameters\n        sage_aggr        = cfg.get(\"sage_aggr\", \"mean\")      # 'mean', 'max', 'add', ...\n        sage_normalize   = cfg.get(\"sage_normalize\", False)  # L2-normalize embeddings\n        sage_root_weight = cfg.get(\"sage_root_weight\", True)\n\n        # Signature in typical PyG versions: SAGEConv(in_channels, out_channels, aggr='mean', normalize=False, root_weight=True...)\n        conv = SAGEConv(\n            in_channels,\n            out_channels,\n            aggr=sage_aggr,\n            normalize=sage_normalize,\n            root_weight=sage_root_weight,\n        )\n        return conv\n\n    elif conv_type == \"nn\":\n        # NNConv-specific hyperparameters\n        if edge_dim is None:\n            raise ValueError(\"NNConv requires edge_dim when using edge_attr.\")\n\n        edge_hidden_dim   = cfg.get(\"nn_edge_hidden_dim\", max(16, edge_dim * 2))\n        edge_mlp_layers   = cfg.get(\"nn_edge_mlp_layers\", 2)\n        nn_aggr           = cfg.get(\"nn_aggr\", \"mean\")  # 'mean' or 'add' typically\n\n        # Build edge MLP: edge_attr -> (in_channels * out_channels)\n        layers = []\n        in_dim = edge_dim\n        for i in range(edge_mlp_layers - 1):\n            layers.append(nn.Linear(in_dim, edge_hidden_dim))\n            layers.append(nn.ReLU())\n            in_dim = edge_hidden_dim\n        layers.append(nn.Linear(in_dim, in_channels * out_channels))\n        edge_mlp = nn.Sequential(*layers)\n\n        conv = NNConv(\n            in_channels,\n            out_channels,\n            edge_mlp,\n            aggr=nn_aggr,\n        )\n        return conv\n\n    elif conv_type == \"gine\":\n        # GINEConv-specific hyperparameters\n        gine_mlp_hidden_dim   = cfg.get(\"gine_mlp_hidden_dim\", out_channels)\n        gine_mlp_layers       = cfg.get(\"gine_mlp_layers\", 2)\n        gine_eps_init         = cfg.get(\"gine_eps_init\", 0.0)\n        gine_train_eps        = cfg.get(\"gine_train_eps\", False)\n\n        # Build MLP on node features\n        layers = []\n        in_dim = in_channels\n        for i in range(gine_mlp_layers - 1):\n            layers.append(nn.Linear(in_dim, gine_mlp_hidden_dim))\n            layers.append(nn.ReLU())\n            in_dim = gine_mlp_hidden_dim\n        layers.append(nn.Linear(in_dim, out_channels))\n        mlp = nn.Sequential(*layers)\n\n        conv = GINEConv(\n            nn=mlp,\n            eps=gine_eps_init,\n            train_eps=gine_train_eps,\n            edge_dim=edge_dim,\n        )\n        return conv\n\n    elif conv_type == \"transformer\":\n        # TransformerConv-specific hyperparameters\n        tr_heads   = cfg.get(\"tr_heads\", 1)\n        tr_concat  = cfg.get(\"tr_concat\", False)  # for simplicity keep False so out_dim == out_channels\n        tr_dropout = cfg.get(\"tr_dropout\", 0.0)\n        tr_beta    = cfg.get(\"tr_beta\", False)\n\n        conv = TransformerConv(\n            in_channels,\n            out_channels,\n            heads=tr_heads,\n            concat=tr_concat,\n            beta=tr_beta,\n            dropout=tr_dropout,\n            edge_dim=edge_dim,\n        )\n        return conv\n\n    else:\n        raise ValueError(f\"Unknown conv_type: {conv_type}\")\n\n\nclass GraphEncoder(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        edge_dim,\n        hidden_dim=64,\n        latent_dim=16,\n        num_layers=3,\n        conv_type=\"gine\",\n        dropout=0.0,\n        conv_config=None,\n    ):\n        super().__init__()\n        self.conv_type = conv_type.lower()\n        self.dropout_layer = nn.Dropout(dropout)\n        self.activ = nn.ReLU()\n        self.conv_config = conv_config or {}\n\n        layers = []\n        # Example: dims = [in_channels, hidden_dim, ..., latent_dim]\n        dims = [in_channels] + [hidden_dim] * (num_layers - 1) + [latent_dim]\n\n        for l in range(len(dims) - 1):\n            in_dim = dims[l]\n            out_dim = dims[l + 1]\n            conv = build_conv_layer(\n                self.conv_type,\n                in_dim,\n                out_dim,\n                edge_dim=edge_dim,\n                conv_config=self.conv_config,\n            )\n            layers.append(conv)\n\n        self.layers = nn.ModuleList(layers)\n\n    def forward(self, x, edge_index, edge_attr=None):\n        for conv in self.layers:\n            if self.conv_type == \"sage\":\n                x = conv(x, edge_index)\n            else:\n                x = conv(x, edge_index, edge_attr)\n            x = self.activ(x)\n            x = self.dropout_layer(x)\n        return x  # node-level latent features\n\n\nclass GAEModel(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        edge_dim,\n        hidden_dim=64,\n        latent_dim=16,\n        num_layers=3,\n        conv_type=\"gine\",\n        dropout=0.0,\n        decoder_hidden_dim=64,\n        conv_config=None,  # NEW\n    ):\n        super().__init__()\n        self.encoder = GraphEncoder(\n            in_channels=in_channels,\n            edge_dim=edge_dim,\n            hidden_dim=hidden_dim,\n            latent_dim=latent_dim,\n            num_layers=num_layers,\n            conv_type=conv_type,\n            dropout=dropout,\n            conv_config=conv_config,\n        )\n\n        # Simple MLP decoder: latent -> reconstructed node features\n        self.decoder = nn.Sequential(\n            nn.Linear(latent_dim, decoder_hidden_dim),\n            nn.ReLU(),\n            nn.Linear(decoder_hidden_dim, in_channels),\n        )\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        edge_attr = getattr(data, \"edge_attr\", None)\n        z = self.encoder(x, edge_index, edge_attr)\n        x_hat = self.decoder(z)\n        return x_hat, z\n\n    def encode(self, data):\n        x, edge_index = data.x, data.edge_index\n        edge_attr = getattr(data, \"edge_attr\", None)\n        return self.encoder(x, edge_index, edge_attr)\n","metadata":{"id":"qgkas4gvuzEX","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T09:00:22.492135Z","iopub.execute_input":"2025-12-05T09:00:22.492480Z","iopub.status.idle":"2025-12-05T09:00:22.511713Z","shell.execute_reply.started":"2025-12-05T09:00:22.492457Z","shell.execute_reply":"2025-12-05T09:00:22.511011Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# ---- Reconstruction loss: MSE + optional exponential term ----\n\ndef reconstruction_loss(x, x_hat, use_exponential=True, alpha=1.0, beta=1.0):\n    \"\"\"\n    x, x_hat: [N_nodes, n_features]\n    L = MSE + alpha * E[exp(beta * MSE_node) - 1]\n    where MSE_node is the per-node mean squared error over features.\n    \"\"\"\n    # Per-node MSE over features\n    mse_per_node = torch.mean((x_hat - x) ** 2, dim=-1)   # [N_nodes]\n    mse = mse_per_node.mean()\n\n    if use_exponential:\n        exp_term = torch.mean(torch.exp(beta * mse_per_node) - 1.0)\n        loss = mse + alpha * exp_term\n    else:\n        # Keep a tensor on the same device for consistency\n        exp_term = torch.zeros(1, device=x.device)\n        loss = mse\n\n    details = {\n        \"mse\": mse.item(),\n        \"exp_term\": exp_term.item(),\n    }\n    return loss, details\n","metadata":{"id":"rv1FQZdpPd_9","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T09:00:22.512635Z","iopub.execute_input":"2025-12-05T09:00:22.512955Z","iopub.status.idle":"2025-12-05T09:00:22.529395Z","shell.execute_reply.started":"2025-12-05T09:00:22.512938Z","shell.execute_reply":"2025-12-05T09:00:22.528837Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\ndef train_epoch(model, loader, optimizer, use_exponential=False, alpha=1.0, beta=1.0):\n    model.train()\n    total_loss = 0.0\n    total_mse = 0.0\n    total_exp = 0.0\n    count = 0\n\n    for data in loader:\n        data = data.to(device)\n        optimizer.zero_grad()\n        x_hat, z = model(data)\n        loss, details = reconstruction_loss(\n            data.x, x_hat,\n            use_exponential=use_exponential,\n            alpha=alpha,\n            beta=beta,\n        )\n        loss.backward()\n        optimizer.step()\n\n        batch_size_nodes = data.x.size(0)\n        total_loss += loss.item() * batch_size_nodes\n        total_mse  += details[\"mse\"] * batch_size_nodes\n        if \"exp\" in details:\n            total_exp += details[\"exp\"] * batch_size_nodes\n        count += batch_size_nodes\n\n    avg_loss = total_loss / count\n    avg_mse  = total_mse  / count\n    avg_exp  = total_exp  / count if use_exponential else 0.0\n\n    return {\n        \"loss\": avg_loss,\n        \"mse\": avg_mse,\n        \"exp\": avg_exp,\n    }\n\n\ndef eval_epoch(model, loader, use_exponential=False, alpha=1.0, beta=1.0):\n    model.eval()\n    total_loss = 0.0\n    total_mse = 0.0\n    total_exp = 0.0\n    count = 0\n\n    with torch.no_grad():\n        for data in loader:\n            data = data.to(device)\n            x_hat, z = model(data)\n            loss, details = reconstruction_loss(\n                data.x, x_hat,\n                use_exponential=use_exponential,\n                alpha=alpha,\n                beta=beta,\n            )\n\n            batch_size_nodes = data.x.size(0)\n            total_loss += loss.item() * batch_size_nodes\n            total_mse  += details[\"mse\"] * batch_size_nodes\n            if \"exp\" in details:\n                total_exp += details[\"exp\"] * batch_size_nodes\n            count += batch_size_nodes\n\n    avg_loss = total_loss / count\n    avg_mse  = total_mse  / count\n    avg_exp  = total_exp  / count if use_exponential else 0.0\n\n    return {\n        \"loss\": avg_loss,\n        \"mse\": avg_mse,\n        \"exp\": avg_exp,\n    }\n\n\ndef train_model(\n    model,\n    train_loader,\n    val_loader,\n    epochs=50,\n    lr=1e-3,\n    weight_decay=0.0,\n    use_exponential=False,\n    alpha=1.0,\n    beta=1.0,\n):\n    model = model.to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n\n    history = {\n        \"train_loss\": [],\n        \"val_loss\": [],\n        \"train_mse\": [],\n        \"val_mse\": [],\n    }\n\n    best_val_loss = float(\"inf\")\n    best_state = None\n\n    for epoch in range(1, epochs + 1):\n        train_stats = train_epoch(\n            model,\n            train_loader,\n            optimizer,\n            use_exponential=use_exponential,\n            alpha=alpha,\n            beta=beta,\n        )\n        val_stats = eval_epoch(\n            model,\n            val_loader,\n            use_exponential=use_exponential,\n            alpha=alpha,\n            beta=beta,\n        )\n\n        history[\"train_loss\"].append(train_stats[\"loss\"])\n        history[\"val_loss\"].append(val_stats[\"loss\"])\n        history[\"train_mse\"].append(train_stats[\"mse\"])\n        history[\"val_mse\"].append(val_stats[\"mse\"])\n\n        if val_stats[\"loss\"] < best_val_loss:\n            best_val_loss = val_stats[\"loss\"]\n            best_state = model.state_dict()\n\n        # print(\n        #     f\"Epoch {epoch:03d} | \"\n        #     f\"Train loss: {train_stats['loss']:.4f}, Val loss: {val_stats['loss']:.4f}\"\n        # )\n\n    # Load best weights\n    if best_state is not None:\n        model.load_state_dict(best_state)\n\n    return model, history\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bN-iikjeuzCG","outputId":"3c34ce6a-dd14-489b-b6ec-88e6e89e392d","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T17:11:49.515646Z","iopub.execute_input":"2025-12-05T17:11:49.515911Z","iopub.status.idle":"2025-12-05T17:11:49.528503Z","shell.execute_reply.started":"2025-12-05T17:11:49.515891Z","shell.execute_reply":"2025-12-05T17:11:49.527778Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"id":"H7I9ERZwuy_c"},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"### Anomaly scores and ROC AUC\n\nWe compute:\n- per-node reconstruction error,\n- per-graph anomaly score (mean reconstruction error),\n- ROC AUC for background (0) vs signal (1) on the test set,\n- histograms of anomaly scores for BG vs signal.\n","metadata":{"id":"Ta_tEm4yzuIy"}},{"cell_type":"code","source":"def compute_anomaly_scores(model, loader):\n    \"\"\"\n    Compute per-graph anomaly scores (mean node-wise MSE) and labels.\n    \"\"\"\n    model.eval()\n    all_scores = []\n    all_labels = []\n\n    with torch.no_grad():\n        for data in loader:\n            data = data.to(device)\n            x_hat, z = model(data)\n\n            # Node-wise MSE\n            mse_per_node = ((data.x - x_hat) ** 2).mean(dim=1)  # [N_nodes]\n            # Pool per graph\n            graph_scores = global_mean_pool(mse_per_node, data.batch)  # [N_graphs]\n\n            all_scores.extend(graph_scores.cpu().numpy().tolist())\n            all_labels.extend(data.y.cpu().numpy().tolist())\n\n    return np.array(all_scores), np.array(all_labels)\n\n\n# test_scores, test_labels_arr = compute_anomaly_scores(model, test_loader)\n# print(\"Anomaly scores shape:\", test_scores.shape)\n# print(\"Test labels shape:\", test_labels_arr.shape)\n\n# # Compute ROC AUC (signal label = 1)\n# auc = roc_auc_score(test_labels_arr, test_scores)\n# print(\"Test ROC AUC:\", auc)\n\n# # Plot histogram of scores\n# plt.figure(figsize=(6, 4))\n# mask_bg = (test_labels_arr == 0)\n# mask_sig = (test_labels_arr == 1)\n# plt.hist(test_scores[mask_bg], bins=50, alpha=0.6, label=\"Background\", density=True)\n# plt.hist(test_scores[mask_sig], bins=50, alpha=0.6, label=\"Signal\",     density=True)\n# plt.xlabel(\"Anomaly score (mean node MSE)\")\n# plt.ylabel(\"Density\")\n# plt.title(f\"Anomaly Score Distribution (AUC = {auc:.3f})\")\n# plt.legend()\n# plt.grid(alpha=0.3)\n\n# scores_hist_path = os.path.join(exp_dir, f\"anomaly_scores_hist_{config['conv_type']}.png\")\n# plt.savefig(scores_hist_path, dpi=150, bbox_inches=\"tight\")\n# plt.close()\n# print(\"Saved anomaly score histogram to:\", scores_hist_path)\n","metadata":{"id":"3D8aIzhAuy9A","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T09:00:22.551917Z","iopub.execute_input":"2025-12-05T09:00:22.552358Z","iopub.status.idle":"2025-12-05T09:00:22.568567Z","shell.execute_reply.started":"2025-12-05T09:00:22.552341Z","shell.execute_reply":"2025-12-05T09:00:22.567799Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def extract_graph_latent(model, loader):\n    \"\"\"\n    Returns:\n        Z_graph: [num_graphs, latent_dim]\n        labels: [num_graphs]\n    \"\"\"\n    model.eval()\n    Z_graph = []\n    labels = []\n\n    with torch.no_grad():\n        for data in loader:\n            data = data.to(device)\n            z_node = model.encode(data)  # [N_nodes, latent_dim]\n            z_graph = global_mean_pool(z_node, data.batch)  # [N_graphs, latent_dim]\n            Z_graph.append(z_graph.cpu().numpy())\n            labels.append(data.y.cpu().numpy())\n\n    Z_graph = np.concatenate(Z_graph, axis=0)\n    labels = np.concatenate(labels, axis=0)\n    return Z_graph, labels\n\n# Z_graph, labels_graph = extract_graph_latent(model, test_loader)\n# print(\"Graph latent shape:\", Z_graph.shape)\n\n# # PCA to 2D\n# pca = PCA(n_components=2, random_state=SEED)\n# Z_pca = pca.fit_transform(Z_graph)\n\n# plt.figure(figsize=(6, 5))\n# mask_bg = (labels_graph == 0)\n# mask_sig = (labels_graph == 1)\n\n# plt.scatter(Z_pca[mask_bg, 0], Z_pca[mask_bg, 1], s=20, alpha=0.6, label=\"Background\")\n# plt.scatter(Z_pca[mask_sig, 0], Z_pca[mask_sig, 1], s=20, alpha=0.6, label=\"Signal\")\n\n# plt.xlabel(\"PC1\")\n# plt.ylabel(\"PC2\")\n# plt.title(f\"Latent PCA (conv = {config['conv_type']})\")\n# plt.legend()\n# plt.grid(alpha=0.3)\n\n# pca_plot_path = os.path.join(exp_dir, f\"latent_pca_{config['conv_type']}.png\")\n# plt.savefig(pca_plot_path, dpi=150, bbox_inches=\"tight\")\n# plt.close()\n# print(\"Saved PCA latent plot to:\", pca_plot_path)\n\n# # Optional: t-SNE (can be slow on large sets). Uncomment if needed.\n# # tsne = TSNE(n_components=2, random_state=SEED, perplexity=30)\n# # Z_tsne = tsne.fit_transform(Z_graph)\n# #\n# # plt.figure(figsize=(6, 5))\n# # plt.scatter(Z_tsne[mask_bg, 0], Z_tsne[mask_bg, 1], s=20, alpha=0.6, label=\"Background\")\n# # plt.scatter(Z_tsne[mask_sig, 0], Z_tsne[mask_sig, 1], s=20, alpha=0.6, label=\"Signal\")\n# # plt.xlabel(\"t-SNE 1\")\n# # plt.ylabel(\"t-SNE 2\")\n# # plt.title(f\"Latent t-SNE (conv = {config['conv_type']})\")\n# # plt.legend()\n# # plt.grid(alpha=0.3)\n# #\n# # tsne_plot_path = os.path.join(exp_dir, f\"latent_tsne_{config['conv_type']}.png\")\n# # plt.savefig(tsne_plot_path, dpi=150, bbox_inches=\"tight\")\n# # plt.close()\n# # print(\"Saved t-SNE latent plot to:\", tsne_plot_path)\n","metadata":{"id":"JvttpTBIuy68","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T09:00:22.569352Z","iopub.execute_input":"2025-12-05T09:00:22.569594Z","iopub.status.idle":"2025-12-05T09:00:22.585493Z","shell.execute_reply.started":"2025-12-05T09:00:22.569580Z","shell.execute_reply":"2025-12-05T09:00:22.584907Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def plot_eta_phi_input_vs_reco_and_save(\n    data,\n    model,\n    device,\n    exp_dir,\n    filename_prefix,\n    title_suffix=\"\",\n):\n    \"\"\"\n    Visualise one event as η–φ scatter plots (input vs reconstruction) and save it.\n\n    IMPORTANT: we clone `data` before moving to device to avoid mutating the\n    original dataset graphs (which would cause CPU/GPU mixing inside DataLoader).\n    \"\"\"\n    model.eval()\n    with torch.no_grad():\n        # Make a deep copy so we do NOT modify the original graph in test_graphs\n        batch = copy.deepcopy(data).to(device)\n        x_hat, z = model(batch)\n        x_hat = x_hat.cpu().numpy()\n\n    # Use the original CPU graph for inputs\n    x_in = data.x.cpu().numpy()\n\n    # Input features\n    pt_in  = x_in[:, 0]\n    eta_in = x_in[:, 1]\n    phi_in = x_in[:, 2]\n\n    # Reconstructed features\n    pt_out  = x_hat[:, 0]\n    eta_out = x_hat[:, 1]\n    phi_out = x_hat[:, 2]\n\n    # Object type from one-hot\n    try:\n        OBJ_TYPES  # noqa: F823\n    except NameError:\n        OBJ_TYPES = [\"MET\", \"e\", \"j\", \"mu\", \"ph\"]\n\n    onehot_in = x_in[:, 3:]\n    type_idx  = onehot_in.argmax(axis=1)\n\n    cmap = mpl.colormaps.get_cmap(\"tab10\")\n\n    def pt_to_size(pt):\n        pt = np.clip(pt, 0, None)\n        if pt.max() <= 0:\n            return np.full_like(pt, 30.0)\n        pt_norm = pt / (pt.max() + 1e-8)\n        return 20.0 + 80.0 * pt_norm\n\n    sizes_in  = pt_to_size(pt_in)\n    sizes_out = pt_to_size(pt_out)\n\n    eta_min = min(eta_in.min(), eta_out.min())\n    eta_max = max(eta_in.max(), eta_out.max())\n    phi_min = min(phi_in.min(), phi_out.min())\n    phi_max = max(phi_in.max(), phi_out.max())\n\n    node_colors = [cmap(int(i)) for i in type_idx]\n\n    fig, axes = plt.subplots(1, 2, figsize=(10, 4), constrained_layout=True)\n\n    # ---- Left: input ----\n    ax = axes[0]\n    ax.scatter(\n        eta_in,\n        phi_in,\n        s=sizes_in,\n        c=node_colors,\n        alpha=0.8,\n        edgecolors=\"k\",\n    )\n    ax.set_xlabel(r\"$\\eta$\")\n    ax.set_ylabel(r\"$\\phi$\")\n    ax.set_title(\"Input features \" + title_suffix)\n    ax.set_xlim(eta_min, eta_max)\n    ax.set_ylim(phi_min, phi_max)\n    ax.grid(True, alpha=0.3)\n\n    # ---- Right: reconstruction ----\n    ax = axes[1]\n    ax.scatter(\n        eta_out,\n        phi_out,\n        s=sizes_out,\n        c=node_colors,\n        alpha=0.8,\n        edgecolors=\"k\",\n    )\n    ax.set_xlabel(r\"$\\eta$\")\n    ax.set_ylabel(r\"$\\phi$\")\n    ax.set_title(\"Reconstructed features \" + title_suffix)\n    ax.set_xlim(eta_min, eta_max)\n    ax.set_ylim(phi_min, phi_max)\n    ax.grid(True, alpha=0.3)\n\n    # Legend for object types\n    handles = []\n    labels  = []\n    for i, name in enumerate(OBJ_TYPES):\n        handles.append(\n            plt.Line2D(\n                [], [],\n                marker=\"o\",\n                linestyle=\"\",\n                markersize=8,\n                markerfacecolor=cmap(i),\n                markeredgecolor=\"k\",\n            )\n        )\n        labels.append(name)\n\n    fig.legend(\n        handles,\n        labels,\n        title=\"Object type\",\n        loc=\"upper center\",\n        bbox_to_anchor=(0.5, 0.02),\n        ncol=len(OBJ_TYPES),\n    )\n\n    os.makedirs(exp_dir, exist_ok=True)\n    save_path = os.path.join(exp_dir, f\"{filename_prefix}.png\")\n    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n    plt.close(fig)\n    print(f\"Saved {filename_prefix} plot to: {save_path}\")\n\n\ndef plot_eta_phi_examples(\n    model,\n    device,\n    test_graphs,\n    test_labels,\n    exp_dir,\n    max_bkg=3,\n    max_sig=3,\n):\n    \"\"\"\n    Pick up to `max_bkg` background and `max_sig` signal graphs from the test set\n    and make η–φ plots for each.\n\n    Note: Uses the updated `plot_eta_phi_input_vs_reco_and_save` which clones graphs.\n    \"\"\"\n    test_labels = np.array(test_labels)\n\n    bkg_indices = np.where(test_labels == 0)[0]\n    sig_indices = np.where(test_labels == 1)[0]\n\n    print(f\"Found {len(bkg_indices)} background and {len(sig_indices)} signal test events.\")\n\n    n_bkg_to_show = min(max_bkg, len(bkg_indices))\n    n_sig_to_show = min(max_sig, len(sig_indices))\n\n    print(f\"Showing {n_bkg_to_show} background and {n_sig_to_show} signal events.\")\n\n    for k in range(n_bkg_to_show):\n        idx = bkg_indices[k]\n        print(f\"\\nBackground example {k+1} (test index = {idx})\")\n        example_bkg = test_graphs[idx]\n        plot_eta_phi_input_vs_reco_and_save(\n            example_bkg,\n            model,\n            device,\n            exp_dir,\n            filename_prefix=f\"bkg_example_{k+1}_eta_phi\",\n            title_suffix=\"(Background)\",\n        )\n\n    for k in range(n_sig_to_show):\n        idx = sig_indices[k]\n        print(f\"\\nSignal example {k+1} (test index = {idx})\")\n        example_sig = test_graphs[idx]\n        plot_eta_phi_input_vs_reco_and_save(\n            example_sig,\n            model,\n            device,\n            exp_dir,\n            filename_prefix=f\"sig_example_{k+1}_eta_phi\",\n            title_suffix=\"(Signal)\",\n        )\n","metadata":{"id":"x09dlzDIzxm-","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T09:00:22.586155Z","iopub.execute_input":"2025-12-05T09:00:22.586443Z","iopub.status.idle":"2025-12-05T09:00:22.605744Z","shell.execute_reply.started":"2025-12-05T09:00:22.586422Z","shell.execute_reply":"2025-12-05T09:00:22.605215Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def run_full_pipeline(\n    ML_dict,\n    dataset=\"all_signals\",\n    conv_type=\"gine\",          # \"sage\", \"nn\", \"gine\", \"transformer\"\n    edge_attr_mode=\"geo_pt\",   # \"geo\" or \"geo_pt\"\n    exp_root=\"/content/drive/MyDrive/Datasets/GAEwEdge\",\n    batch_size=64,\n    hidden_dim=64,\n    latent_dim=16,\n    num_layers=3,\n    dropout=0.0,\n    decoder_hidden_dim=64,\n    epochs=50,\n    lr=1e-3,\n    weight_decay=0.0,\n    use_exponential=True,\n    alpha=1.0,\n    beta=1.0,\n    max_bkg_eta_phi=3,\n    max_sig_eta_phi=3,\n    conv_config=None,\n):\n    \"\"\"\n    Main driver function: run the full GAE pipeline for a given dataset key in ML_dict.\n    \"\"\"\n\n    print(f\"\\n=== Running pipeline for dataset = '{dataset}' ===\")\n    if dataset not in ML_dict:\n        raise KeyError(f\"Dataset key '{dataset}' not found in ML_dict. Available: {list(ML_dict.keys())}\")\n\n    # 1) Select dataframe for this dataset\n    df = ML_dict[dataset].copy()\n    print(\"Dataset shape:\", df.shape)\n\n    # 2) Background vs signal split\n    BG_LABEL = \"EB_test\"\n    df_bg = df[df[\"target\"] == BG_LABEL].reset_index(drop=True)\n    df_sig = df[df[\"target\"] != BG_LABEL].reset_index(drop=True)\n\n    df_bg[\"y\"] = 0\n    df_sig[\"y\"] = 1\n\n    print(\"Background events:\", len(df_bg))\n    print(\"Signal events:\", len(df_sig))\n\n    # 3) Train/val/test split (BG only for train/val, BG+SIG for test)\n    df_bg_train, df_bg_temp = train_test_split(\n        df_bg, test_size=0.3, random_state=SEED, shuffle=True\n    )\n    df_bg_val, df_bg_test_bg = train_test_split(\n        df_bg_temp, test_size=0.5, random_state=SEED, shuffle=True\n    )\n\n    df_test = pd.concat([df_bg_test_bg, df_sig], ignore_index=True)\n\n    print(\"Train BG:\", len(df_bg_train))\n    print(\"Val BG:\", len(df_bg_val))\n    print(\"Test BG:\", len(df_bg_test_bg))\n    print(\"Total test events:\", len(df_test))\n    print(\"Test label counts:\\n\", df_test[\"y\"].value_counts())\n\n    # 4) Fit node feature scaler on background training events\n    global node_feature_scaler\n    node_feature_scaler = fit_node_feature_scaler(df_bg_train)\n\n    # 5) Build graphs\n    train_graphs, train_labels, train_samples = build_graph_dataset(df_bg_train, edge_attr_mode=edge_attr_mode)\n    val_graphs,   val_labels,   val_samples   = build_graph_dataset(df_bg_val,   edge_attr_mode=edge_attr_mode)\n    test_graphs,  test_labels,  test_samples  = build_graph_dataset(df_test,     edge_attr_mode=edge_attr_mode)\n\n    print(f\"Train graphs: {len(train_graphs)}\")\n    print(f\"Val graphs:   {len(val_graphs)}\")\n    print(f\"Test graphs:  {len(test_graphs)}\")\n\n    # 6) DataLoaders\n    train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n    val_loader   = DataLoader(val_graphs,   batch_size=batch_size, shuffle=False)\n    test_loader  = DataLoader(test_graphs,  batch_size=batch_size, shuffle=False)\n\n    # 7) Experiment directory for this dataset + conv_type\n    exp_dir = os.path.join(exp_root, f\"{dataset}_{conv_type}\")\n    os.makedirs(exp_dir, exist_ok=True)\n    print(\"Experiment directory:\", exp_dir)\n\n    # 8) Infer input & edge dimensions\n    in_channels = train_graphs[0].x.shape[1]\n    edge_dim = train_graphs[0].edge_attr.shape[1]\n\n    print(\"in_channels (node features):\", in_channels)\n    print(\"edge_dim (edge attributes):\", edge_dim)\n\n    # 9) Build and train model\n    model = GAEModel(\n        in_channels=in_channels,\n        edge_dim=edge_dim,\n        hidden_dim=hidden_dim,\n        latent_dim=latent_dim,\n        num_layers=num_layers,\n        conv_type=conv_type,\n        dropout=dropout,\n        decoder_hidden_dim=decoder_hidden_dim,\n    )\n\n    config = {\n        \"conv_type\": conv_type,\n        \"hidden_dim\": hidden_dim,\n        \"latent_dim\": latent_dim,\n        \"num_layers\": num_layers,\n        \"dropout\": dropout,\n        \"decoder_hidden_dim\": decoder_hidden_dim,\n        \"epochs\": epochs,\n        \"lr\": lr,\n        \"weight_decay\": weight_decay,\n        \"use_exponential\": use_exponential,\n        \"alpha\": alpha,\n        \"beta\": beta,\n        \"edge_attr_mode\": edge_attr_mode,\n        \"dataset\": dataset,\n        \"batch_size\": batch_size,\n    }\n\n    print(\"\\nTraining configuration:\", config)\n\n    model, history = train_model(\n        model,\n        train_loader,\n        val_loader,\n        epochs=epochs,\n        lr=lr,\n        weight_decay=weight_decay,\n        use_exponential=use_exponential,\n        alpha=alpha,\n        beta=beta,\n    )\n\n    # 10) Plot & save training/validation loss\n    epochs_arr = np.arange(1, epochs + 1)\n    plt.figure(figsize=(6, 4))\n    plt.plot(epochs_arr, history[\"train_loss\"], label=\"Train loss\")\n    plt.plot(epochs_arr, history[\"val_loss\"],   label=\"Val loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(f\"Training vs Validation Loss ({conv_type}, dataset={dataset})\")\n    plt.legend()\n    plt.grid(alpha=0.3)\n\n    loss_plot_path = os.path.join(exp_dir, f\"loss_curve_{dataset}_{conv_type}.png\")\n    plt.savefig(loss_plot_path, dpi=150, bbox_inches=\"tight\")\n    plt.close()\n    print(\"Saved loss curve to:\", loss_plot_path)\n\n    # 11) Anomaly scores, ROC, and histogram\n    test_scores, test_labels_arr = compute_anomaly_scores(model, test_loader)\n    auc = roc_auc_score(test_labels_arr, test_scores)\n    print(\"Test ROC AUC:\", auc)\n\n    plt.figure(figsize=(6, 4))\n    mask_bg = (test_labels_arr == 0)\n    mask_sig = (test_labels_arr == 1)\n    plt.hist(test_scores[mask_bg], bins=50, alpha=0.6, label=\"Background\", density=True)\n    plt.hist(test_scores[mask_sig], bins=50, alpha=0.6, label=\"Signal\",     density=True)\n    plt.xlabel(\"Anomaly score (mean node MSE)\")\n    plt.ylabel(\"Density\")\n    plt.title(f\"Anomaly Score Dist (AUC = {auc:.3f}, {dataset}, {conv_type})\")\n    plt.legend()\n    plt.grid(alpha=0.3)\n\n    scores_hist_path = os.path.join(exp_dir, f\"anomaly_scores_hist_{dataset}_{conv_type}.png\")\n    plt.savefig(scores_hist_path, dpi=150, bbox_inches=\"tight\")\n    plt.close()\n    print(\"Saved anomaly score histogram to:\", scores_hist_path)\n\n    # 12) Latent PCA\n    Z_graph, labels_graph = extract_graph_latent(model, test_loader)\n    print(\"Graph latent shape:\", Z_graph.shape)\n\n    pca = PCA(n_components=2, random_state=SEED)\n    Z_pca = pca.fit_transform(Z_graph)\n\n    plt.figure(figsize=(6, 5))\n    mask_bg_p = (labels_graph == 0)\n    mask_sig_p = (labels_graph == 1)\n    plt.scatter(Z_pca[mask_bg_p, 0], Z_pca[mask_bg_p, 1], s=20, alpha=0.6, label=\"Background\")\n    plt.scatter(Z_pca[mask_sig_p, 0], Z_pca[mask_sig_p, 1], s=20, alpha=0.6, label=\"Signal\")\n\n    plt.xlabel(\"PC1\")\n    plt.ylabel(\"PC2\")\n    plt.title(f\"Latent PCA ({dataset}, {conv_type})\")\n    plt.legend()\n    plt.grid(alpha=0.3)\n\n    pca_plot_path = os.path.join(exp_dir, f\"latent_pca_{dataset}_{conv_type}.png\")\n    plt.savefig(pca_plot_path, dpi=150, bbox_inches=\"tight\")\n    plt.close()\n    print(\"Saved PCA latent plot to:\", pca_plot_path)\n\n    # 13) η–φ examples (input vs reconstruction)\n    plot_eta_phi_examples(\n        model,\n        device,\n        test_graphs,\n        test_labels,\n        exp_dir,\n        max_bkg=max_bkg_eta_phi,\n        max_sig=max_sig_eta_phi,\n    )\n\n    # 14) Return everything useful\n    results = {\n        \"model\": model,\n        \"exp_dir\": exp_dir,\n        \"config\": config,\n        \"history\": history,\n        \"test_auc\": auc,\n        \"test_scores\": test_scores,\n        \"test_labels\": test_labels_arr,\n    }\n    print(\"\\n=== Pipeline finished for dataset =\", dataset, \"===\")\n    return results\n","metadata":{"id":"iUiUlUyu3krd","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T09:00:22.606594Z","iopub.execute_input":"2025-12-05T09:00:22.607291Z","iopub.status.idle":"2025-12-05T09:00:22.628124Z","shell.execute_reply.started":"2025-12-05T09:00:22.607262Z","shell.execute_reply":"2025-12-05T09:00:22.627425Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Hyperparameter grid search\n\nWe now define a small grid search over:\n- `conv_type` ∈ {`\"sage\"`, `\"nn\"`, `\"gine\"`, `\"transformer\"`}\n- `hidden_dim`, `latent_dim`, `lr`\n\nMetric: **validation reconstruction loss** (background-only).\nYou can extend / shrink this grid as needed.\n","metadata":{"id":"YMBxfGpL0INN"}},{"cell_type":"code","source":"def prepare_loaders_for_dataset(\n    ML_dict,\n    dataset=\"all_signals\",\n    edge_attr_mode=\"geo_pt\",\n    batch_size=64,\n    max_bg_events_for_gs=2000,   # NEW: limit number of background events\n):\n    \"\"\"\n    Prepare train/val DataLoaders, in_channels, and edge_dim for a given dataset key in ML_dict,\n    using ONLY a subset of background events (for fast grid search).\n\n    - We randomly sample up to `max_bg_events_for_gs` background events.\n    - Then we split that subset into train/val and build graphs.\n\n    This is meant specifically for grid search, not for final training.\n    \"\"\"\n    print(f\"\\n=== Preparing loaders for dataset = '{dataset}' (for grid search) ===\")\n    if dataset not in ML_dict:\n        raise KeyError(f\"Dataset key '{dataset}' not found in ML_dict. Available: {list(ML_dict.keys())}\")\n\n    df = ML_dict[dataset].copy()\n    BG_LABEL = \"EB_test\"\n\n    df_bg = df[df[\"target\"] == BG_LABEL].reset_index(drop=True)\n    df_sig = df[df[\"target\"] != BG_LABEL].reset_index(drop=True)\n\n    df_bg[\"y\"] = 0\n    df_sig[\"y\"] = 1  # signal unused here, but kept for consistency\n\n    print(\"Total background events available:\", len(df_bg))\n    print(\"Total signal events (unused for grid search):\", len(df_sig))\n\n    # ---- Subsample background for grid search ----\n    if max_bg_events_for_gs is not None and len(df_bg) > max_bg_events_for_gs:\n        df_bg = df_bg.sample(\n            n=max_bg_events_for_gs,\n            random_state=SEED,\n            replace=False,\n        ).reset_index(drop=True)\n        print(f\"Subsampled background events to: {len(df_bg)} for grid search.\")\n    else:\n        print(\"Using all available background events for grid search subset.\")\n\n    # ---- Train/val split on this subset ----\n    df_bg_train, df_bg_val = train_test_split(\n        df_bg, test_size=0.3, random_state=SEED, shuffle=True\n    )\n\n    print(\"Grid-search Train BG:\", len(df_bg_train))\n    print(\"Grid-search Val BG:\", len(df_bg_val))\n\n    # Fit scaler on training background subset\n    global node_feature_scaler\n    node_feature_scaler = fit_node_feature_scaler(df_bg_train)\n\n    # Build graphs\n    train_graphs, _, _ = build_graph_dataset(df_bg_train, edge_attr_mode=edge_attr_mode)\n    val_graphs,   _, _ = build_graph_dataset(df_bg_val,   edge_attr_mode=edge_attr_mode)\n\n    print(f\"Train graphs: {len(train_graphs)}\")\n    print(f\"Val graphs:   {len(val_graphs)}\")\n\n    train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n    val_loader   = DataLoader(val_graphs,   batch_size=batch_size, shuffle=False)\n\n    in_channels = train_graphs[0].x.shape[1]\n    edge_dim    = train_graphs[0].edge_attr.shape[1]\n\n    print(\"in_channels (node features):\", in_channels)\n    print(\"edge_dim (edge attributes):\", edge_dim)\n\n    return train_loader, val_loader, in_channels, edge_dim\n","metadata":{"id":"IuIe3mct9vQk","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T16:58:45.710065Z","iopub.execute_input":"2025-12-05T16:58:45.710389Z","iopub.status.idle":"2025-12-05T16:58:45.719374Z","shell.execute_reply.started":"2025-12-05T16:58:45.710367Z","shell.execute_reply":"2025-12-05T16:58:45.718608Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from itertools import product\n\ndef run_extended_grid_search(\n    train_loader,\n    val_loader,\n    in_channels,\n    edge_dim,\n    dataset_name=\"all_signals\",\n    use_exponential=True,\n    alpha=1.0,\n    beta=1.0,\n):\n    \"\"\"\n    Extended grid search over:\n      - Global hyperparameters: hidden_dim, latent_dim, num_layers, lr, dropout\n      - Convolution-specific hyperparameters (small grids per conv_type)\n\n    Returns:\n      results_df: DataFrame of all runs\n      best_by_conv: dict conv_type -> best row (as dict)\n    \"\"\"\n    conv_types = [\"sage\", \"nn\", \"gine\", \"transformer\"]\n\n    # Global hyperparameter ranges (keep modest for Colab)\n    hidden_dims   = [32, 64, 128]\n    latent_dims   = [8, 16, 32]\n    num_layers_l  = [2, 3]\n    lrs           = [1e-4, 5e-4, 1e-3]\n    dropouts      = [0.0, 0.1, 0.2]\n\n    results = []\n\n    def run_single_config(\n        conv_type,\n        global_cfg,\n        conv_cfg,\n        epochs=10,  # shorten for grid search\n    ):\n        \"\"\"\n        Train a single configuration and return best validation loss.\n        \"\"\"\n        print(\n            f\"\\n=== conv={conv_type}, \"\n            f\"hid={global_cfg['hidden_dim']}, lat={global_cfg['latent_dim']}, \"\n            f\"layers={global_cfg['num_layers']}, lr={global_cfg['lr']}, \"\n            f\"drop={global_cfg['dropout']}, conv_cfg={conv_cfg} ===\"\n        )\n\n        model_gs = GAEModel(\n            in_channels=in_channels,\n            edge_dim=edge_dim,\n            hidden_dim=global_cfg[\"hidden_dim\"],\n            latent_dim=global_cfg[\"latent_dim\"],\n            num_layers=global_cfg[\"num_layers\"],\n            conv_type=conv_type,\n            dropout=global_cfg[\"dropout\"],\n            decoder_hidden_dim=global_cfg[\"hidden_dim\"],\n            conv_config=conv_cfg,\n        )\n\n        model_gs, hist_gs = train_model(\n            model_gs,\n            train_loader,\n            val_loader,\n            epochs=epochs,\n            lr=global_cfg[\"lr\"],\n            weight_decay=0.0,\n            use_exponential=use_exponential,\n            alpha=alpha,\n            beta=beta,\n        )\n\n        best_val_loss = min(hist_gs[\"val_loss\"])\n        print(f\"--> Best val loss for this config: {best_val_loss:.6f}\")\n        return best_val_loss\n\n    for conv_type in conv_types:\n        # Define a small conv-specific grid for this conv_type\n        if conv_type == \"sage\":\n            conv_specific_grid = [\n                {\"sage_aggr\": \"mean\"},\n                {\"sage_aggr\": \"max\"},\n            ]\n        elif conv_type == \"nn\":\n            conv_specific_grid = [\n                {\"nn_edge_hidden_dim\": 32, \"nn_edge_mlp_layers\": 1, \"nn_aggr\": \"mean\"},\n                {\"nn_edge_hidden_dim\": 64, \"nn_edge_mlp_layers\": 2, \"nn_aggr\": \"mean\"},\n            ]\n        elif conv_type == \"gine\":\n            conv_specific_grid = [\n                {\n                    \"gine_mlp_hidden_dim\": None,  # None -> default = out_channels\n                    \"gine_mlp_layers\": 2,\n                    \"gine_train_eps\": False,\n                    \"gine_eps_init\": 0.0,\n                },\n                {\n                    \"gine_mlp_hidden_dim\": None,\n                    \"gine_mlp_layers\": 3,\n                    \"gine_train_eps\": True,\n                    \"gine_eps_init\": 0.0,\n                },\n            ]\n        elif conv_type == \"transformer\":\n            conv_specific_grid = [\n                {\"tr_heads\": 1, \"tr_concat\": False, \"tr_dropout\": 0.0, \"tr_beta\": False},\n                {\"tr_heads\": 2, \"tr_concat\": False, \"tr_dropout\": 0.2, \"tr_beta\": True},\n            ]\n        else:\n            conv_specific_grid = [{}]\n\n        # Global hyperparameters\n        for hdim, ldim, nl, lr, do in product(\n            hidden_dims, latent_dims, num_layers_l, lrs, dropouts\n        ):\n            global_cfg = {\n                \"hidden_dim\": hdim,\n                \"latent_dim\": ldim,\n                \"num_layers\": nl,\n                \"lr\": lr,\n                \"dropout\": do,\n            }\n\n            for conv_cfg_base in conv_specific_grid:\n                # Fill in defaults where needed\n                conv_cfg = dict(conv_cfg_base)  # copy\n                # If GINE-specific MLP hidden dim is None, set to hidden_dim\n                if conv_type == \"gine\" and conv_cfg.get(\"gine_mlp_hidden_dim\") is None:\n                    conv_cfg[\"gine_mlp_hidden_dim\"] = hdim\n\n                best_val_loss = run_single_config(conv_type, global_cfg, conv_cfg)\n\n                results.append({\n                    \"dataset\": dataset_name,\n                    \"conv_type\": conv_type,\n                    \"hidden_dim\": hdim,\n                    \"latent_dim\": ldim,\n                    \"num_layers\": nl,\n                    \"lr\": lr,\n                    \"dropout\": do,\n                    \"best_val_loss\": best_val_loss,\n                    # Conv-specific stuff (some columns will be NaN for other convs)\n                    \"sage_aggr\": conv_cfg.get(\"sage_aggr\"),\n                    \"nn_edge_hidden_dim\": conv_cfg.get(\"nn_edge_hidden_dim\"),\n                    \"nn_edge_mlp_layers\": conv_cfg.get(\"nn_edge_mlp_layers\"),\n                    \"nn_aggr\": conv_cfg.get(\"nn_aggr\"),\n                    \"gine_mlp_hidden_dim\": conv_cfg.get(\"gine_mlp_hidden_dim\"),\n                    \"gine_mlp_layers\": conv_cfg.get(\"gine_mlp_layers\"),\n                    \"gine_train_eps\": conv_cfg.get(\"gine_train_eps\"),\n                    \"gine_eps_init\": conv_cfg.get(\"gine_eps_init\"),\n                    \"tr_heads\": conv_cfg.get(\"tr_heads\"),\n                    \"tr_concat\": conv_cfg.get(\"tr_concat\"),\n                    \"tr_dropout\": conv_cfg.get(\"tr_dropout\"),\n                    \"tr_beta\": conv_cfg.get(\"tr_beta\"),\n                })\n\n    results_df = pd.DataFrame(results)\n\n    print(\"\\n===== Full extended grid search results (sorted globally) =====\")\n    print(results_df.sort_values(\"best_val_loss\").head(20))  # top 20 for brevity\n\n    # Best configuration per conv_type\n    print(\"\\n===== Best configuration per conv_type =====\")\n    best_by_conv = {}\n    for ct in conv_types:\n        sub = results_df[results_df[\"conv_type\"] == ct]\n        if len(sub) == 0:\n            continue\n        best_row = sub.loc[sub[\"best_val_loss\"].idxmin()]\n        best_by_conv[ct] = best_row.to_dict()\n        print(\n            f\"\\nConv type: {ct}\\n\"\n            f\"  hidden_dim      = {best_row['hidden_dim']}\\n\"\n            f\"  latent_dim      = {best_row['latent_dim']}\\n\"\n            f\"  num_layers      = {best_row['num_layers']}\\n\"\n            f\"  lr              = {best_row['lr']}\\n\"\n            f\"  dropout         = {best_row['dropout']}\\n\"\n            f\"  best_val_loss   = {best_row['best_val_loss']:.6f}\"\n        )\n        if ct == \"sage\":\n            print(f\"  sage_aggr       = {best_row['sage_aggr']}\")\n        elif ct == \"nn\":\n            print(\n                f\"  nn_edge_hidden_dim = {best_row['nn_edge_hidden_dim']}, \"\n                f\"nn_edge_mlp_layers = {best_row['nn_edge_mlp_layers']}, \"\n                f\"nn_aggr = {best_row['nn_aggr']}\"\n            )\n        elif ct == \"gine\":\n            print(\n                f\"  gine_mlp_hidden_dim = {best_row['gine_mlp_hidden_dim']}, \"\n                f\"gine_mlp_layers = {best_row['gine_mlp_layers']}, \"\n                f\"gine_train_eps = {best_row['gine_train_eps']}, \"\n                f\"gine_eps_init = {best_row['gine_eps_init']}\"\n            )\n        elif ct == \"transformer\":\n            print(\n                f\"  tr_heads = {best_row['tr_heads']}, \"\n                f\"tr_dropout = {best_row['tr_dropout']}, \"\n                f\"tr_beta = {best_row['tr_beta']}\"\n            )\n\n    return results_df, best_by_conv\n","metadata":{"id":"OCsrGDQZzxiT","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T09:00:22.646385Z","iopub.execute_input":"2025-12-05T09:00:22.646619Z","iopub.status.idle":"2025-12-05T09:00:22.665215Z","shell.execute_reply.started":"2025-12-05T09:00:22.646596Z","shell.execute_reply":"2025-12-05T09:00:22.664583Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# 1) Prepare loaders for the dataset you want to tune on\ntrain_loader, val_loader, in_channels, edge_dim = prepare_loaders_for_dataset(\n    ML_dict,\n    dataset=\"all_signals\",\n    edge_attr_mode=\"geo_pt\",\n    batch_size=64,\n    max_bg_events_for_gs=2000,   # ← here you control how many BG events to use\n)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9e91eNn_HrB","outputId":"6ab9c0d5-b37d-4918-b8f9-1c74568559b5","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T17:10:05.738079Z","iopub.execute_input":"2025-12-05T17:10:05.738735Z","iopub.status.idle":"2025-12-05T17:10:07.477183Z","shell.execute_reply.started":"2025-12-05T17:10:05.738709Z","shell.execute_reply":"2025-12-05T17:10:07.476459Z"}},"outputs":[{"name":"stdout","text":"\n=== Preparing loaders for dataset = 'all_signals' (for grid search) ===\nTotal background events available: 317657\nTotal signal events (unused for grid search): 317657\nSubsampled background events to: 2000 for grid search.\nGrid-search Train BG: 1400\nGrid-search Val BG: 600\nCollected node feature samples for scaler: (7887, 3)\nNode feature scaler mean: [2.10414636e+01 8.35084668e-03 4.12605667e-02]\nNode feature scaler scale: [9.87374194 1.42385701 1.80853129]\nTrain graphs: 1272\nVal graphs:   528\nin_channels (node features): 8\nedge_dim (edge attributes): 6\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"def pretty_print_best_by_conv(best_by_conv):\n    \"\"\"\n    Nicely print best_by_conv as a small summary table.\n\n    best_by_conv is the dict returned by run_extended_grid_search, of the form:\n        { conv_type: row_dict_from_results_df, ... }\n    \"\"\"\n    if not best_by_conv:\n        print(\"best_by_conv is empty.\")\n        return None\n\n    # Turn values (row dicts) into a DataFrame\n    rows = list(best_by_conv.values())\n    df = pd.DataFrame(rows)\n\n    # Choose a sensible column order\n    preferred_cols = [\n        \"dataset\",\n        \"conv_type\",\n        \"hidden_dim\",\n        \"latent_dim\",\n        \"num_layers\",\n        \"lr\",\n        \"dropout\",\n        \"best_val_loss\",\n        # conv-specific (will be NaN where not applicable)\n        \"sage_aggr\",\n        \"nn_edge_hidden_dim\",\n        \"nn_edge_mlp_layers\",\n        \"nn_aggr\",\n        \"gine_mlp_hidden_dim\",\n        \"gine_mlp_layers\",\n        \"gine_train_eps\",\n        \"gine_eps_init\",\n        \"tr_heads\",\n        \"tr_dropout\",\n        \"tr_beta\",\n    ]\n\n    cols = [c for c in preferred_cols if c in df.columns]\n    df = df[cols]\n\n    # Sort by best_val_loss ascending\n    if \"best_val_loss\" in df.columns:\n        df = df.sort_values(\"best_val_loss\")\n\n    print(\"\\n===== best_by_conv summary =====\")\n    print(df.to_string(index=False))\n\n    return df\n\n\ndef build_conv_config_from_best(conv_type, best_row):\n    \"\"\"\n    Extract conv-specific hyperparameters from a best_row dict\n    (one entry of best_by_conv) and build a conv_config dict\n    suitable for passing into GAEModel / GraphEncoder.\n    \"\"\"\n    conv_type = conv_type.lower()\n    cfg = {}\n\n    if conv_type == \"sage\":\n        cfg[\"sage_aggr\"] = best_row.get(\"sage_aggr\", \"mean\")\n\n    elif conv_type == \"nn\":\n        if pd.isna(best_row.get(\"nn_edge_hidden_dim\", np.nan)):\n            pass\n        else:\n            cfg[\"nn_edge_hidden_dim\"] = int(best_row[\"nn_edge_hidden_dim\"])\n        if pd.isna(best_row.get(\"nn_edge_mlp_layers\", np.nan)):\n            pass\n        else:\n            cfg[\"nn_edge_mlp_layers\"] = int(best_row[\"nn_edge_mlp_layers\"])\n        if pd.isna(best_row.get(\"nn_aggr\", np.nan)):\n            pass\n        else:\n            cfg[\"nn_aggr\"] = best_row[\"nn_aggr\"]\n\n    elif conv_type == \"gine\":\n        if not pd.isna(best_row.get(\"gine_mlp_hidden_dim\", np.nan)):\n            cfg[\"gine_mlp_hidden_dim\"] = int(best_row[\"gine_mlp_hidden_dim\"])\n        if not pd.isna(best_row.get(\"gine_mlp_layers\", np.nan)):\n            cfg[\"gine_mlp_layers\"] = int(best_row[\"gine_mlp_layers\"])\n        if not pd.isna(best_row.get(\"gine_train_eps\", np.nan)):\n            cfg[\"gine_train_eps\"] = bool(best_row[\"gine_train_eps\"])\n        if not pd.isna(best_row.get(\"gine_eps_init\", np.nan)):\n            cfg[\"gine_eps_init\"] = float(best_row[\"gine_eps_init\"])\n\n    elif conv_type == \"transformer\":\n        if not pd.isna(best_row.get(\"tr_heads\", np.nan)):\n            cfg[\"tr_heads\"] = int(best_row[\"tr_heads\"])\n        if not pd.isna(best_row.get(\"tr_concat\", np.nan)):\n            cfg[\"tr_concat\"] = bool(best_row[\"tr_concat\"])\n        if not pd.isna(best_row.get(\"tr_dropout\", np.nan)):\n            cfg[\"tr_dropout\"] = float(best_row[\"tr_dropout\"])\n        if not pd.isna(best_row.get(\"tr_beta\", np.nan)):\n            cfg[\"tr_beta\"] = bool(best_row[\"tr_beta\"])\n\n    return cfg\n\n\ndef run_full_from_best(\n    ML_dict,\n    best_by_conv,\n    conv_type,\n    dataset=\"all_signals\",\n    edge_attr_mode=\"geo_pt\",\n    exp_root=\"gae_experiments\",\n    epochs=50,\n    batch_size=64,\n    use_exponential=True,\n    alpha=1.0,\n    beta=1.0,\n):\n    \"\"\"\n    Convenience helper:\n    Take best_by_conv[conv_type] from the extended grid search,\n    and run the full pipeline (training + all plots) with matching hyperparameters.\n\n    NOTE:\n    - Assumes run_full_pipeline(...) has a 'conv_config' argument and passes it to GAEModel.\n    \"\"\"\n    ct = conv_type.lower()\n    if ct not in best_by_conv:\n        raise KeyError(f\"conv_type '{ct}' not found in best_by_conv. Keys: {list(best_by_conv.keys())}\")\n\n    best_row = best_by_conv[ct]\n\n    # Extract global hyperparameters\n    hidden_dim = int(best_row[\"hidden_dim\"])\n    latent_dim = int(best_row[\"latent_dim\"])\n    num_layers = int(best_row[\"num_layers\"])\n    lr = float(best_row[\"lr\"])\n    dropout = float(best_row[\"dropout\"])\n\n    # Build conv-specific config dict\n    conv_config = build_conv_config_from_best(ct, best_row)\n\n    print(f\"\\n>>> Running full pipeline for dataset='{dataset}', conv_type='{ct}'\")\n    print(f\"    Using best global hyperparameters from grid search:\")\n    print(f\"      hidden_dim  = {hidden_dim}\")\n    print(f\"      latent_dim  = {latent_dim}\")\n    print(f\"      num_layers  = {num_layers}\")\n    print(f\"      lr          = {lr}\")\n    print(f\"      dropout     = {dropout}\")\n    print(f\"    Conv-specific config: {conv_config}\")\n\n    # IMPORTANT:\n    # Make sure your run_full_pipeline signature includes 'conv_config=None'\n    # and passes it to GAEModel(..., conv_config=conv_config).\n    results = run_full_pipeline(\n        ML_dict,\n        dataset=dataset,\n        conv_type=ct,\n        edge_attr_mode=edge_attr_mode,\n        exp_root=exp_root,\n        batch_size=batch_size,\n        hidden_dim=hidden_dim,\n        latent_dim=latent_dim,\n        num_layers=num_layers,\n        dropout=dropout,\n        decoder_hidden_dim=hidden_dim,  # you can change if you want\n        epochs=epochs,\n        lr=lr,\n        weight_decay=0.0,\n        use_exponential=use_exponential,\n        alpha=alpha,\n        beta=beta,\n        max_bkg_eta_phi=3,\n        max_sig_eta_phi=3,\n        conv_config=conv_config,\n    )\n\n    return results\n","metadata":{"id":"fZ2Uls8s_KfY","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T16:59:44.775354Z","iopub.execute_input":"2025-12-05T16:59:44.775895Z","iopub.status.idle":"2025-12-05T16:59:44.789921Z","shell.execute_reply.started":"2025-12-05T16:59:44.775871Z","shell.execute_reply":"2025-12-05T16:59:44.789056Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"results_df, best_by_conv = run_extended_grid_search(\n    train_loader,\n    val_loader,\n    in_channels,\n    edge_dim,\n    use_exponential=False,\n    dataset_name=\"all_signals\",\n)\n\n# Neatly print best_by_conv\nsummary_df = pretty_print_best_by_conv(best_by_conv)\n\n# Then, say you want to run the full pipeline for the best GINE config:\n# results_gine = run_full_from_best(\n#     ML_dict,\n#     best_by_conv,\n#     conv_type=\"gine\",\n#     dataset=\"all_signals\",\n#     edge_attr_mode=\"geo_pt\",\n#     epochs=50,\n# )\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-NaVwBb4_teY","outputId":"c4538597-f487-4b26-a900-a7490ea8ec1d","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T17:12:01.834381Z","iopub.execute_input":"2025-12-05T17:12:01.834662Z","iopub.status.idle":"2025-12-05T17:51:04.604859Z","shell.execute_reply.started":"2025-12-05T17:12:01.834640Z","shell.execute_reply":"2025-12-05T17:51:04.603957Z"}},"outputs":[{"name":"stdout","text":"\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.421556\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.413530\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.445864\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.394501\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.441793\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.405721\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.110466\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.094467\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.093812\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.103712\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.095844\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.260606\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.023685\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.039744\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.046082\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.055220\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.077756\n\n=== conv=sage, hid=32, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.078127\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.436984\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.381534\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.470254\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.394321\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.440061\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.383669\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.126997\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.042242\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.084983\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.117005\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.158567\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.173254\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.025625\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.025486\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.067486\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.056284\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.082374\n\n=== conv=sage, hid=32, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.105410\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.398676\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.393043\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.409385\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.381198\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.432634\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.404253\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.036220\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.040726\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.044694\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.059413\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.075136\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.083307\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.017147\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.015937\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.030718\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.033619\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.045078\n\n=== conv=sage, hid=32, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.053222\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.462063\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.369243\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.436104\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.371783\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.421520\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.398485\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.038623\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.036380\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.065114\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.073415\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.135634\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.094344\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.019757\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.026354\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.043079\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.056445\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.054938\n\n=== conv=sage, hid=32, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.079339\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.395820\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.352808\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.398905\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.342443\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.371869\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.395683\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.028162\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.026969\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.040852\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.052328\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.049064\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.071174\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.011936\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.012095\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.015244\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.025160\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.023237\n\n=== conv=sage, hid=32, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.042202\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.355032\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.383537\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.405262\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.373135\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.365939\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.392180\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.032931\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.064850\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.043974\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.067671\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.058433\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.087007\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.021674\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.017958\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.028421\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.043669\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.040580\n\n=== conv=sage, hid=32, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.067649\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.313805\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.353336\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.378168\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.374901\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.416043\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.389037\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.027288\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.035024\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.055703\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.056501\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.065540\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.086274\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.007727\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.014241\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.029939\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.032551\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.041998\n\n=== conv=sage, hid=64, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.063816\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.323435\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.285838\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.319152\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.345520\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.352690\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.365060\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.017638\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.033707\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.042322\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.067089\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.071800\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.086449\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.015101\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.014066\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.023148\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.040214\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.050745\n\n=== conv=sage, hid=64, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.067089\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.283076\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.344137\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.326043\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.329849\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.352612\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.339539\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.014797\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.022635\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.026085\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.051575\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.038913\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.052663\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.007296\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.010353\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.014811\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.019307\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.026044\n\n=== conv=sage, hid=64, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.035409\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.293340\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.292454\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.315599\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.320951\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.295018\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.340060\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.013732\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.022437\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.033293\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.041985\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.041715\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.072678\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.006009\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.013619\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.021212\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.026894\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.029706\n\n=== conv=sage, hid=64, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.056108\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.270190\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.254677\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.283528\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.322079\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.265924\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.308998\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.010193\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.014042\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.030536\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.027264\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.028126\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.044125\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.004542\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.007375\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.009541\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.012423\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.014911\n\n=== conv=sage, hid=64, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.022365\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.302837\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.256377\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.246638\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.305078\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.267831\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.336583\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.013231\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.015948\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.021636\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.033242\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.035425\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.057890\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.004980\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.010788\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.012247\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.025259\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.018844\n\n=== conv=sage, hid=64, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.042623\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.241237\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.275942\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.269884\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.296453\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.252277\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.291401\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.009803\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.017668\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.030232\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.069781\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.047186\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.057888\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.004119\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.011701\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.020574\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.040455\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.036937\n\n=== conv=sage, hid=128, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.079624\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.149724\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.120891\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.109701\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.134685\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.168274\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.235497\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.009272\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.012498\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.031697\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.033844\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.043045\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.073077\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.032534\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.009557\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.023419\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.044188\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.037415\n\n=== conv=sage, hid=128, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.056068\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.214223\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.226197\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.189389\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.238502\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.215653\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.241486\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.009017\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.011760\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.015631\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.023902\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.029510\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.038089\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.002665\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.005812\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.010685\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.013546\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.020966\n\n=== conv=sage, hid=128, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.025763\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.096122\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.110647\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.160672\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.184596\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.118465\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.207429\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.007107\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.008861\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.016104\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.028727\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.031269\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.060273\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.003596\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.006132\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.011973\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.028864\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.026614\n\n=== conv=sage, hid=128, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.050790\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.136972\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.123409\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.144367\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.136380\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.120318\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.153257\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.005731\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.008979\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.010357\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.014288\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.018092\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.024727\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.001946\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.003439\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.005013\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.006726\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.009465\n\n=== conv=sage, hid=128, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.012324\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.071651\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.062224\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.056236\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.093629\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.074770\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.166486\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.006460\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.008904\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.011376\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.018585\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.018500\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.036604\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.002018\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.007417\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.006745\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.013019\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'mean'} ===\n--> Best val loss for this config: 0.012480\n\n=== conv=sage, hid=128, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'sage_aggr': 'max'} ===\n--> Best val loss for this config: 0.033867\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.383444\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.226801\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.485694\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.331401\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.519650\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.360639\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.267940\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.047963\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.310998\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.075328\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.425973\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.106547\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.115185\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.024362\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.278290\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.046093\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.229789\n\n=== conv=nn, hid=32, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.075674\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 2.388891\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.160492\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.692479\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.362392\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 13.372546\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.413019\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.525037\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.122520\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.480403\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.099525\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.482504\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.110589\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.425184\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.153140\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.413088\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.061747\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.352416\n\n=== conv=nn, hid=32, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.198704\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.497767\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.187196\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.486868\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.223085\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.396157\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.300015\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.258899\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.034887\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.232677\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.055605\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.330828\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.060616\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.113623\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.027777\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.114488\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.039079\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.220436\n\n=== conv=nn, hid=32, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.066077\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 2.919286\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.183705\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 2.392355\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.208505\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 2.874202\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.261717\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.405888\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.111943\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.428368\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.077013\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.448113\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.163614\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.380240\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.035507\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.370217\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.066122\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.416852\n\n=== conv=nn, hid=32, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.107217\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.480869\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.108704\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.468877\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.139540\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.522420\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.120642\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.170709\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.032176\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.233607\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.040123\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.243943\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.046410\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.080487\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.018004\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.128277\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.021582\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.170766\n\n=== conv=nn, hid=32, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.034113\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 1.800981\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.139152\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 2.876624\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.180325\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 1.944703\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.192387\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.529868\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.038672\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.451833\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.056259\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.507047\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.065984\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.356280\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.038103\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.414852\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.036847\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.372639\n\n=== conv=nn, hid=32, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.058959\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.490564\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.101646\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.510486\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.134611\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.497598\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.305053\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.202808\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.033009\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.285879\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.218926\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.271698\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.081196\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.104104\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.018070\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.113222\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.044716\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.291548\n\n=== conv=nn, hid=64, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.205817\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 2.288300\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.307116\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 8.181064\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.293573\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 3.073626\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.377599\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.535418\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.101616\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.467593\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.302709\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.494272\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.286817\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.487356\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.396363\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.422479\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.301713\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.422610\n\n=== conv=nn, hid=64, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.315693\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.510321\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.131193\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.455869\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.154186\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.435945\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.152086\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.199100\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.029925\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.235149\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.037928\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.289562\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.064270\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.093335\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.017262\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.102003\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.028390\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.224052\n\n=== conv=nn, hid=64, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.044183\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 5.021459\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.149214\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 6.616080\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.244809\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 6.808257\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.256056\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.516716\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.041539\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.535736\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.100135\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.554206\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.257330\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.445168\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.148849\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.413023\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.205652\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.453317\n\n=== conv=nn, hid=64, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.191122\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.476669\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.055988\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.479844\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.075029\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.557454\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.159612\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.181374\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.019323\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.198368\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.031325\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.254122\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.036971\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.075096\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.011656\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.166190\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.023372\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.147332\n\n=== conv=nn, hid=64, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.027979\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 4.580373\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.122562\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 3.400962\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.209528\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 7.306906\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.240840\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 1.315456\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.051887\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.486014\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.076505\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.528826\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.085726\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.628209\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.036417\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.450779\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.056163\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.425699\n\n=== conv=nn, hid=64, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.062430\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.437602\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.118339\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.380978\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.114219\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.421584\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.201972\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.237941\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.035169\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.246587\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.097936\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.340506\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.109402\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.196893\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.029675\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.319483\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.067463\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.286878\n\n=== conv=nn, hid=128, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.204434\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 1.097163\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.431682\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 2.719080\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.358744\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 1.616653\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.444551\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.498760\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.299452\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.459269\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.397234\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.442872\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.401363\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.429790\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.396316\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.428194\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.396104\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.449229\n\n=== conv=nn, hid=128, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.396214\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.385814\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.065039\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.395375\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.079762\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.426334\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.098895\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.195263\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.020607\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.206122\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.041176\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.301855\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.071772\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.102642\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.013340\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.214924\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.025892\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.303916\n\n=== conv=nn, hid=128, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.062824\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 15.115864\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.257787\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 2.676041\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.214325\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 5.541547\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.391693\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.708616\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.175246\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.480991\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.400398\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.553070\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.331775\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.457437\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.150606\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.439093\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.395971\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.453399\n\n=== conv=nn, hid=128, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.396889\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.422291\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.061381\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.566709\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.086790\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.528743\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.100170\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.177562\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.013974\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.202904\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.026893\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.275209\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.039242\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.093930\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.014769\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.121490\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.017325\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.196548\n\n=== conv=nn, hid=128, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.031018\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 20.503880\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.203633\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 2.331421\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.159278\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 10.804266\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.323467\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 1.439980\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.058938\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.614896\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.110892\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.530688\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.206526\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.518734\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.041749\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.452629\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.204582\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 32, 'nn_edge_mlp_layers': 1, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.477159\n\n=== conv=nn, hid=128, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'nn_edge_hidden_dim': 64, 'nn_edge_mlp_layers': 2, 'nn_aggr': 'mean'} ===\n--> Best val loss for this config: 0.189761\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.343903\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.351286\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.356248\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.336871\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.474048\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.414701\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.221672\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.263441\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.274524\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.231057\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.273747\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.204049\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.156162\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.156469\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.155691\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.172222\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.181567\n\n=== conv=gine, hid=32, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.168305\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.372508\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.408767\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.390029\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.337799\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.339523\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.370910\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.268981\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.281681\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.209126\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.255930\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.201453\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.280461\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.168633\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.170966\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.191703\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.179343\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.232041\n\n=== conv=gine, hid=32, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.173454\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.334223\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.344405\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.310834\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.359504\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.363054\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.366239\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.154775\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.169893\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.175314\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.174074\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.164501\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.196889\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.164561\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.163498\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.155975\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.167058\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.167089\n\n=== conv=gine, hid=32, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.164860\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.313089\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.358834\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.344409\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.320902\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.366624\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.353318\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.186029\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.179452\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.178219\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.185184\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.279433\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.197023\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.163770\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.173972\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.168285\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.168160\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.186807\n\n=== conv=gine, hid=32, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.171915\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.331879\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.313425\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.335674\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.345283\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.320321\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.361475\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.162149\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.172334\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.161450\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.179029\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.190086\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.170719\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.151579\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.161076\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.126294\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.161407\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.127622\n\n=== conv=gine, hid=32, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.162931\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.318941\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.307539\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.349989\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.315414\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.380086\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.333473\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.178855\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.167434\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.175935\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.185063\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.199085\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.180753\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.168070\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.162057\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.166038\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.160811\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.169445\n\n=== conv=gine, hid=32, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 32, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.161599\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.319377\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.286807\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.296666\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.371571\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.319585\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.333792\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.173078\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.152346\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.194955\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.157696\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.304400\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.178746\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.159764\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.156739\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.183006\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.156440\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.167254\n\n=== conv=gine, hid=64, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.163459\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.265980\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.275669\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.298246\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.272631\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.339676\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.262208\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.156170\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.168485\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.208430\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.165775\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.185437\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.181799\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.148611\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.156258\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.158849\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.157807\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.192951\n\n=== conv=gine, hid=64, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.167841\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.237646\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.223645\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.265921\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.301750\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.304173\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.286962\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.106827\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.160975\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.166948\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.154740\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.180698\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.171819\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.144082\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.135827\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.152754\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.127112\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.155933\n\n=== conv=gine, hid=64, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.165327\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.245377\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.274762\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.251968\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.280585\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.335058\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.286420\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.155618\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.157812\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.159501\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.168711\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.177076\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.165506\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.150307\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.157819\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.153107\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.161115\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.162658\n\n=== conv=gine, hid=64, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.159933\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.253115\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.229834\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.247793\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.235484\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.293061\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.251794\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.135770\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.152441\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.165901\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.160512\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.159991\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.161864\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.117349\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.057835\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.120675\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.122873\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.138223\n\n=== conv=gine, hid=64, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.150367\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.215070\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.242929\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.265395\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.278555\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.275745\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.246082\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.155966\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.164307\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.157542\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.156907\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.174366\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.163616\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.148564\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.156395\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.152349\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.156611\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.150406\n\n=== conv=gine, hid=64, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 64, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.157453\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.306702\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.230805\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.203716\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.189830\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.262453\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.245182\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.102086\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.087144\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.213909\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.160172\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.183085\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.166474\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.079534\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.066768\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.155395\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.078163\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.166996\n\n=== conv=gine, hid=128, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.155916\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.273477\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.199379\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.270048\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.231184\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.255883\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.209767\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.170957\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.161795\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.167622\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.158457\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.181897\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.181315\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.161300\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.153898\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.293222\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.174278\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.184890\n\n=== conv=gine, hid=128, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.172936\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.179226\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.171188\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.195510\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.199634\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.219000\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.201531\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.105180\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.140078\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.058105\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.157995\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.153935\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.124361\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.141392\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.033903\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.141409\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.118001\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.146580\n\n=== conv=gine, hid=128, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.160551\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.172383\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.188097\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.196732\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.218124\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.241006\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.189589\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.151171\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.149328\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.164348\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.160644\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.163165\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.160674\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.157274\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.139912\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.162731\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.157131\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.162819\n\n=== conv=gine, hid=128, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.161306\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.174666\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.163631\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.198811\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.180693\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.208594\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.190498\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.048458\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.139985\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.146997\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.120536\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.136528\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.065985\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.106263\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.136678\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.097750\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.124976\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.037962\n\n=== conv=gine, hid=128, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.103343\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.166873\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.189226\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.225635\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.181846\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.202197\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.213164\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.153193\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.145221\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.148843\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.155475\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.154790\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.158535\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.140854\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.152172\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.141668\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.154607\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 2, 'gine_train_eps': False, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.154329\n\n=== conv=gine, hid=128, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'gine_mlp_hidden_dim': 128, 'gine_mlp_layers': 3, 'gine_train_eps': True, 'gine_eps_init': 0.0} ===\n--> Best val loss for this config: 0.159316\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.365052\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.484360\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.330884\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.420058\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.397492\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.448608\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.096504\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.268162\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.120035\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.186752\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.186801\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.296939\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.029133\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.040736\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.060716\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.046470\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.071857\n\n=== conv=transformer, hid=32, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.059822\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.369242\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.430380\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.397300\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.478746\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.431977\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.416646\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.074131\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.252836\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.117316\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.240851\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.129028\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.257498\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.035777\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.033442\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.055630\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.150158\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.092725\n\n=== conv=transformer, hid=32, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.077511\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.373362\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.422029\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.356333\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.392756\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.375158\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.382128\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.183343\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.203158\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.056257\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.050377\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.092523\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.234092\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.020319\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.142050\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.040344\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.040562\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.045821\n\n=== conv=transformer, hid=32, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.049918\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.352566\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.419376\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.342087\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.389009\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.395925\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.397205\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.044331\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.257991\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.114170\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.257392\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.089566\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.243117\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.015431\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.162370\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.038949\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.170459\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.061565\n\n=== conv=transformer, hid=32, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.163854\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.346160\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.383056\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.329532\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.393135\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.306782\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.401335\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.041300\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.107911\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.045313\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.156198\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.091076\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.053728\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.012050\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.034872\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.029109\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.025105\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.037295\n\n=== conv=transformer, hid=32, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.021256\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.335787\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.396024\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.301994\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.384653\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.358107\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.359182\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.035246\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.174712\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.059467\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.186537\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.070232\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.200921\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.023682\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.160251\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.035028\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.031316\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.042348\n\n=== conv=transformer, hid=32, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.170768\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.351475\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.377580\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.288995\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.390093\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.319365\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.387607\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.033426\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.127512\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.054291\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.051527\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.110951\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.223779\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.012064\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.008921\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.030940\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.039040\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.062549\n\n=== conv=transformer, hid=64, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.042350\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.258594\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.354716\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.306341\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.398788\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.318198\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.380438\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.032148\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.170305\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.063597\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.053443\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.077977\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.223023\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.024697\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.009395\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.042452\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.046087\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.086152\n\n=== conv=transformer, hid=64, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.059760\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.294145\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.399923\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.315668\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.373122\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.299053\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.353774\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.030392\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.030287\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.045403\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.029959\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.059661\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.042806\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.018416\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.078903\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.028957\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.014903\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.036916\n\n=== conv=transformer, hid=64, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.029111\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.270702\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.364567\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.298248\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.341153\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.294574\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.344340\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.034003\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.175639\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.037667\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.071833\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.063879\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.205493\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.017659\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.137509\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.030380\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.160625\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.040999\n\n=== conv=transformer, hid=64, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.028974\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.250126\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.325514\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.252223\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.309107\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.260743\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.368648\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.019249\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.010735\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.035225\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.052416\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.042448\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.027471\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.006400\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.005743\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.017462\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.007461\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.026482\n\n=== conv=transformer, hid=64, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.014570\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.241283\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.313516\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.224980\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.313377\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.245155\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.313965\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.026385\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.166956\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.033923\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.169250\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.048055\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.047886\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.008791\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.071997\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.017302\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.021780\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.031024\n\n=== conv=transformer, hid=64, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.025366\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.232862\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.340910\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.235186\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.343159\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.302397\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.298853\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.015764\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.026715\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.039297\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.040159\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.078756\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.076911\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.008776\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.003432\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.044148\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.024579\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.048385\n\n=== conv=transformer, hid=128, lat=8, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.029118\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.240131\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.306464\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.117504\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.325253\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.257082\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.308564\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.021295\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.075635\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.036038\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.172365\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.062303\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.191115\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.008520\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.007062\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.031939\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.016348\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.050561\n\n=== conv=transformer, hid=128, lat=8, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.046288\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.188420\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.327945\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.218871\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.325384\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.278007\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.349765\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.010594\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.062082\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.028942\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.015880\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.045904\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.030006\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.005719\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.002850\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.013764\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.008771\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.032866\n\n=== conv=transformer, hid=128, lat=16, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.016717\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.111488\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.278690\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.150506\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.280239\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.258576\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.291141\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.015174\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.155838\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.032037\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.176407\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.044620\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.161655\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.004441\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.006384\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.027277\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.008887\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.036674\n\n=== conv=transformer, hid=128, lat=16, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.082725\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.115729\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.260816\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.128804\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.281421\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.174654\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.285470\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.009487\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.008142\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.016095\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.010400\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.027027\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.015007\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.003123\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.003529\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.009180\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.005240\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.014767\n\n=== conv=transformer, hid=128, lat=32, layers=2, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.006905\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.085441\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.0001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.268043\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.077619\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.0001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.278036\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.143694\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.0001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.283222\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.013175\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.0005, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.147503\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.025154\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.0005, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.052804\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.034039\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.0005, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.018242\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.004868\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.001, drop=0.0, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.003105\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.011675\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.001, drop=0.1, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.009362\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 1, 'tr_concat': False, 'tr_dropout': 0.0, 'tr_beta': False} ===\n--> Best val loss for this config: 0.023054\n\n=== conv=transformer, hid=128, lat=32, layers=3, lr=0.001, drop=0.2, conv_cfg={'tr_heads': 2, 'tr_concat': False, 'tr_dropout': 0.2, 'tr_beta': True} ===\n--> Best val loss for this config: 0.011834\n\n===== Full extended grid search results (sorted globally) =====\n          dataset    conv_type  hidden_dim  latent_dim  num_layers      lr  \\\n300   all_signals         sage         128          32           2  0.0010   \n318   all_signals         sage         128          32           3  0.0010   \n264   all_signals         sage         128          16           2  0.0010   \n1237  all_signals  transformer         128          16           2  0.0010   \n1291  all_signals  transformer         128          32           3  0.0010   \n1272  all_signals  transformer         128          32           2  0.0010   \n1201  all_signals  transformer         128           8           2  0.0010   \n301   all_signals         sage         128          32           2  0.0010   \n1273  all_signals  transformer         128          32           2  0.0010   \n282   all_signals         sage         128          16           3  0.0010   \n228   all_signals         sage         128           8           2  0.0010   \n1254  all_signals  transformer         128          16           3  0.0010   \n192   all_signals         sage          64          32           2  0.0010   \n1290  all_signals  transformer         128          32           3  0.0010   \n210   all_signals         sage          64          32           3  0.0010   \n302   all_signals         sage         128          32           2  0.0010   \n1275  all_signals  transformer         128          32           2  0.0010   \n1236  all_signals  transformer         128          16           2  0.0010   \n294   all_signals         sage         128          32           2  0.0005   \n1165  all_signals  transformer          64          32           2  0.0010   \n\n      dropout  best_val_loss sage_aggr  nn_edge_hidden_dim  \\\n300       0.0       0.001946      mean                 NaN   \n318       0.0       0.002018      mean                 NaN   \n264       0.0       0.002665      mean                 NaN   \n1237      0.0       0.002850      None                 NaN   \n1291      0.0       0.003105      None                 NaN   \n1272      0.0       0.003123      None                 NaN   \n1201      0.0       0.003432      None                 NaN   \n301       0.0       0.003439       max                 NaN   \n1273      0.0       0.003529      None                 NaN   \n282       0.0       0.003596      mean                 NaN   \n228       0.0       0.004119      mean                 NaN   \n1254      0.0       0.004441      None                 NaN   \n192       0.0       0.004542      mean                 NaN   \n1290      0.0       0.004868      None                 NaN   \n210       0.0       0.004980      mean                 NaN   \n302       0.1       0.005013      mean                 NaN   \n1275      0.1       0.005240      None                 NaN   \n1236      0.0       0.005719      None                 NaN   \n294       0.0       0.005731      mean                 NaN   \n1165      0.0       0.005743      None                 NaN   \n\n      nn_edge_mlp_layers nn_aggr  gine_mlp_hidden_dim  gine_mlp_layers  \\\n300                  NaN    None                  NaN              NaN   \n318                  NaN    None                  NaN              NaN   \n264                  NaN    None                  NaN              NaN   \n1237                 NaN    None                  NaN              NaN   \n1291                 NaN    None                  NaN              NaN   \n1272                 NaN    None                  NaN              NaN   \n1201                 NaN    None                  NaN              NaN   \n301                  NaN    None                  NaN              NaN   \n1273                 NaN    None                  NaN              NaN   \n282                  NaN    None                  NaN              NaN   \n228                  NaN    None                  NaN              NaN   \n1254                 NaN    None                  NaN              NaN   \n192                  NaN    None                  NaN              NaN   \n1290                 NaN    None                  NaN              NaN   \n210                  NaN    None                  NaN              NaN   \n302                  NaN    None                  NaN              NaN   \n1275                 NaN    None                  NaN              NaN   \n1236                 NaN    None                  NaN              NaN   \n294                  NaN    None                  NaN              NaN   \n1165                 NaN    None                  NaN              NaN   \n\n     gine_train_eps  gine_eps_init  tr_heads tr_concat  tr_dropout tr_beta  \n300            None            NaN       NaN      None         NaN    None  \n318            None            NaN       NaN      None         NaN    None  \n264            None            NaN       NaN      None         NaN    None  \n1237           None            NaN       2.0     False         0.2    True  \n1291           None            NaN       2.0     False         0.2    True  \n1272           None            NaN       1.0     False         0.0   False  \n1201           None            NaN       2.0     False         0.2    True  \n301            None            NaN       NaN      None         NaN    None  \n1273           None            NaN       2.0     False         0.2    True  \n282            None            NaN       NaN      None         NaN    None  \n228            None            NaN       NaN      None         NaN    None  \n1254           None            NaN       1.0     False         0.0   False  \n192            None            NaN       NaN      None         NaN    None  \n1290           None            NaN       1.0     False         0.0   False  \n210            None            NaN       NaN      None         NaN    None  \n302            None            NaN       NaN      None         NaN    None  \n1275           None            NaN       2.0     False         0.2    True  \n1236           None            NaN       1.0     False         0.0   False  \n294            None            NaN       NaN      None         NaN    None  \n1165           None            NaN       2.0     False         0.2    True  \n\n===== Best configuration per conv_type =====\n\nConv type: sage\n  hidden_dim      = 128\n  latent_dim      = 32\n  num_layers      = 2\n  lr              = 0.001\n  dropout         = 0.0\n  best_val_loss   = 0.001946\n  sage_aggr       = mean\n\nConv type: nn\n  hidden_dim      = 64\n  latent_dim      = 32\n  num_layers      = 2\n  lr              = 0.001\n  dropout         = 0.0\n  best_val_loss   = 0.011656\n  nn_edge_hidden_dim = 64.0, nn_edge_mlp_layers = 2.0, nn_aggr = mean\n\nConv type: gine\n  hidden_dim      = 128\n  latent_dim      = 16\n  num_layers      = 2\n  lr              = 0.001\n  dropout         = 0.0\n  best_val_loss   = 0.033903\n  gine_mlp_hidden_dim = 128.0, gine_mlp_layers = 3.0, gine_train_eps = True, gine_eps_init = 0.0\n\nConv type: transformer\n  hidden_dim      = 128\n  latent_dim      = 16\n  num_layers      = 2\n  lr              = 0.001\n  dropout         = 0.0\n  best_val_loss   = 0.002850\n  tr_heads = 2.0, tr_dropout = 0.2, tr_beta = True\n\n===== best_by_conv summary =====\n    dataset   conv_type  hidden_dim  latent_dim  num_layers    lr  dropout  best_val_loss sage_aggr  nn_edge_hidden_dim  nn_edge_mlp_layers nn_aggr  gine_mlp_hidden_dim  gine_mlp_layers gine_train_eps  gine_eps_init  tr_heads  tr_dropout tr_beta\nall_signals        sage         128          32           2 0.001      0.0       0.001946      mean                 NaN                 NaN    None                  NaN              NaN           None            NaN       NaN         NaN    None\nall_signals transformer         128          16           2 0.001      0.0       0.002850      None                 NaN                 NaN    None                  NaN              NaN           None            NaN       2.0         0.2    True\nall_signals          nn          64          32           2 0.001      0.0       0.011656      None                64.0                 2.0    mean                  NaN              NaN           None            NaN       NaN         NaN    None\nall_signals        gine         128          16           2 0.001      0.0       0.033903      None                 NaN                 NaN    None                128.0              3.0           True            0.0       NaN         NaN    None\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"## Driver: run_full_pipeline(ML_dict, dataset=..., ...)\n\nThis function is the main entry point.  \nYou call it once at the end, and it:\n\n1. Picks `df = ML_dict[dataset]`.\n2. Splits into background (`target == \"EB_test\"`) and signal.\n3. Trains a GAE (background only) with the chosen convolution.\n4. Produces and saves:\n   - training/validation loss curve,\n   - anomaly score histogram + ROC AUC,\n   - latent PCA plot,\n   - η–φ input vs reconstruction plots for a few BG & signal events.\n","metadata":{"id":"Kpw1vvtR3cEJ"}},{"cell_type":"code","source":"# Example: run on the combined dataset 'all_signals'\nresults_all = run_full_pipeline(\n    ML_dict,\n    dataset=\"all_signals\",   # or \"Znunu\", \"HNLeemu\", etc.\n    conv_type=\"gine\",        # \"sage\", \"nn\", \"gine\", \"transformer\"\n    edge_attr_mode=\"geo_pt\", # geometric + log pT edge attributes\n    epochs=50,\n    hidden_dim=64,\n    latent_dim=16,\n)\n\n# Example: run on a specific dataset, e.g. only Znunu vs EB_test\n# results_znunu = run_full_pipeline(ML_dict, dataset=\"Znunu\", conv_type=\"nn\")\n","metadata":{"id":"gmBu-glG0I94"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"C9uKHDhO0JCT"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"-gS5VzfN_oLI"},"outputs":[],"execution_count":null}]}